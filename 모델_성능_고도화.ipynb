{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshOne91/PLAYDATA-COLAB/blob/main/%EB%AA%A8%EB%8D%B8_%EC%84%B1%EB%8A%A5_%EA%B3%A0%EB%8F%84%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "CdxDv7umBAiV",
        "outputId": "0b317020-9542-42b5-8988-b8830ec25e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.2 (from autogluon)\n",
            "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.14.1)\n",
            "Collecting scikit-learn<1.5.3,>=1.4.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading boto3-1.37.34-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2->autogluon) (18.1.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2->autogluon) (0.2.7)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.2->autogluon) (11.1.0)\n",
            "Collecting torch<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: transformers<5,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (4.51.1)\n",
            "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.21.0,>=0.16.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting scikit-image<0.25.0,>=0.19.1 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.2->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.2->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.2->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.2->autogluon) (2.18.0)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting numpy<2.1.4,>=1.25.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy<3.8 (from autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (0.8.1)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (2.1.4)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (2.7.19)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.2->autogluon) (0.30.2)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading gluonts-0.16.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading statsforecast-1.7.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (28 kB)\n",
            "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.10.16)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (5.9.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2025.3.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (24.2)\n",
            "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (0.5.3)\n",
            "Collecting botocore<1.38.0,>=1.37.34 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading botocore-1.37.34-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.17.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (1.7.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (1.0.3)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.11.3)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.13.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.24.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.8.2)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (2024.11.6)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.18.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.29.4)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.11.15)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.21.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading virtualenv-20.30.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.71.0)\n",
            "Collecting memray (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading memray-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2025.1.31)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.0.9)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.14.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (0.21.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (0.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.19.0)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (4.13.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.0.1)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
            "  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.1.5)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.18.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.3.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.17.2)\n",
            "Collecting textual>=0.41.0 (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading textual-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.24.2)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.0.40)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (9.1.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.69.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.38.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (2.6)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.9)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
            "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.0/430.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.34-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl (66.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-1.7.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.37.34-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.30.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading memray-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading textual-3.1.0-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.8/683.8 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=b1366bb4462c596daf3b7e1a51fba14352b8acc774a2448b0ddc6d82215c8a4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=90e8fb3f545a9aa84d1362f193eb1ef54b0d3ae2ab6d1196b66fb63f3c292939\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=e3a6bd39d6feb14b01260422ee1e370382b8a36d081cb6a4f79c36098b75f54d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, appdirs, antlr4-python3-runtime, xxhash, virtualenv, triton, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nltk, lightning-utilities, jmespath, fsspec, fs, dill, colorlog, colorama, tensorboardX, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, coreforecast, botocore, blis, alembic, window-ops, utilsforecast, triad, scikit-learn, scikit-image, s3transfer, optuna, opendatalab, nvidia-cusolver-cu12, jsonschema, gluonts, aiohttp-cors, torch, thinc, textual, seqeval, ray, openmim, opencensus, nlpaug, mlforecast, datasets, catboost, boto3, adagio, torchvision, torchmetrics, spacy, pytorch-metric-learning, memray, fugue, evaluate, autogluon.common, accelerate, timm, statsforecast, pytorch-lightning, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.25.2\n",
            "    Uninstalling scikit-image-0.25.2:\n",
            "      Successfully uninstalled scikit-image-0.25.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.5\n",
            "    Uninstalling spacy-3.8.5:\n",
            "      Successfully uninstalled spacy-3.8.5\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.34.2 adagio-0.2.6 aiohttp-cors-0.8.1 alembic-1.15.2 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 blis-0.7.11 boto3-1.37.34 botocore-1.37.34 catboost-1.2.8 colorama-0.4.6 colorful-0.5.6 colorlog-6.9.0 coreforecast-0.0.12 datasets-3.5.0 dill-0.3.8 distlib-0.3.9 evaluate-0.4.3 fs-2.4.16 fsspec-2024.12.0 fugue-0.9.1 gluonts-0.16.1 jmespath-1.0.1 jsonschema-4.21.1 lightning-2.5.1 lightning-utilities-0.14.3 memray-1.17.1 mlforecast-0.13.4 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nltk-3.8.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.3.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.0 pycryptodome-3.22.0 pytesseract-0.3.10 pytorch-lightning-2.5.1 pytorch-metric-learning-2.3.0 ray-2.39.0 s3transfer-0.11.4 scikit-image-0.24.0 scikit-learn-1.5.2 seqeval-1.2.2 spacy-3.7.5 statsforecast-1.7.8 tensorboardX-2.6.2.2 textual-3.1.0 thinc-8.2.5 timm-1.0.3 torch-2.5.1 torchmetrics-1.2.1 torchvision-0.20.1 triad-0.9.8 triton-3.1.0 utilsforecast-0.2.4 virtualenv-20.30.0 window-ops-0.0.15 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "3438de0f2cfa42258a926fae54e36712"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터는 mnist\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, Compose\n",
        "# 데이터 전처리\n",
        "transforms = Compose([ToTensor()])\n",
        "train_data = MNIST(root='./', download=True, transform=transforms, train=True)\n",
        "test_data =  MNIST(root='./', download=True, transform=transforms,train=False)\n",
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04FZSRam70K5",
        "outputId": "ff1bb67a-fec2-46e2-939d-0668a6ee9fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터는 2D형태로 변환\n",
        "import torch\n",
        "X_train = torch.flatten(train_data.data, start_dim=1)  # torch.flatten(train_data.data[0])\n",
        "y_train = train_data.targets\n",
        "X_test = torch.flatten(test_data.data, start_dim=1)\n",
        "y_test = test_data.targets\n",
        "\n",
        "X_train.shape, y_train.shape,  X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO_G9NnX9bZf",
        "outputId": "2f5f5175-415c-4ca8-824c-d4b09f97d9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]),\n",
              " torch.Size([60000]),\n",
              " torch.Size([10000, 784]),\n",
              " torch.Size([10000]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BiIsl1YkII3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe 으로 변환\n",
        "train_df = pd.DataFrame(X_train)\n",
        "train_df['target'] = y_train\n",
        "test_df = pd.DataFrame(X_test)\n",
        "test_df['target'] = y_test"
      ],
      "metadata": {
        "id": "mDZgP9sEJ9Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TabularDataset\n",
        "train_data = TabularDataset(train_df)\n",
        "test_data = TabularDataset(test_df)"
      ],
      "metadata": {
        "id": "VZEqspceKFAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간설정 (10분)\n",
        "time_limit = 60*10 # 1h : 60*60\n",
        "# gpu 사용불가 모델은 제외\n",
        "eval_metric = 'f1_weighted'  # 평가방법  이진분류는 roc_auc  다중분류 roc_auc_ovo\n",
        "excluded_model_types = [\n",
        "    'KNN','RF','XT','LR','NN'\n",
        "]\n",
        "# AutoGluon 학습\n",
        "predictor = TabularPredictor(label='target',path='AutogluonModels/',eval_metric=eval_metric) \\\n",
        ".fit(train_data,time_limit = time_limit,excluded_model_types=excluded_model_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7JQC97zMKTyc",
        "outputId": "2d6439f3-bff1-4428-8e03-56ecfc6111c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
            "Disk Space Avail:   65.50 GB / 112.64 GB (58.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels\"\n",
            "Train Data Rows:    60000\n",
            "Train Data Columns: 784\n",
            "Label Column:       target\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t10 unique label values:  [5, 0, 4, 1, 9, 2, 3, 6, 7, 8]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 10\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11133.94 MB\n",
            "\tTrain Data (Original)  Memory Usage: 44.86 MB (0.4% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 17 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 67): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '52', '53', '54', '55', '56', '57', '82', '83', '84', '85', '111', '112', '140', '141', '168', '476', '560', '644', '645', '671', '672', '673', '699', '700', '701', '727', '728', '729', '730', '754', '755', '756', '757', '758', '759', '780', '781', '782', '783']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 73): ['13', '14', '15', '32', '33', '34', '35', '47', '48', '49', '50', '51', '58', '59', '60', '61', '81', '86', '110', '114', '138', '139', '142', '169', '170', '195', '196', '197', '223', '224', '225', '336', '362', '363', '364', '391', '392', '419', '420', '421', '422', '447', '448', '450', '504', '505', '531', '532', '559', '587', '588', '615', '616', '642', '643', '670', '674', '698', '702', '703', '724', '725', '726', '731', '732', '752', '753', '760', '761', '776', '777', '778', '779']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('int', []) : 73 | ['13', '14', '15', '32', '33', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', []) : 644 | ['12', '36', '37', '38', '39', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('int', [])       : 643 | ['12', '36', '37', '38', '39', ...]\n",
            "\t\t('int', ['bool']) :   1 | ['113']\n",
            "\t4.1s = Fit runtime\n",
            "\t644 features in original data used to generate 644 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 36.85 MB (0.3% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.55s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.041666666666666664, Train Rows: 57500, Val Rows: 2500\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 7 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 595.45s of the 595.45s of remaining time.\n",
            "\t0.9872\t = Validation score   (f1_weighted)\n",
            "\t106.03s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 489.20s of the 489.19s of remaining time.\n",
            "\tRan out of time, early stopping on iteration 484. Best iteration is:\n",
            "\t[394]\tvalid_set's multi_logloss: 0.054067\tvalid_set's f1_weighted: 0.98401\n",
            "\t0.984\t = Validation score   (f1_weighted)\n",
            "\t495.07s\t = Training   runtime\n",
            "\t1.19s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -7.66s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.714, 'LightGBMXT': 0.286}\n",
            "\t0.988\t = Validation score   (f1_weighted)\n",
            "\t0.12s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 608.03s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1914.1 rows/s (2500 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard = predictor.leaderboard(silent=True)\n",
        "leaderboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "lhA5MwYFKkvD",
        "outputId": "262e3a8a-eb12-4f6e-98a4-388f4a8fd2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 model  score_val  eval_metric  pred_time_val    fit_time  \\\n",
              "0  WeightedEnsemble_L2   0.988003  f1_weighted       1.306103  601.223051   \n",
              "1      NeuralNetFastAI   0.987198  f1_weighted       0.110458  106.030788   \n",
              "2           LightGBMXT   0.984010  f1_weighted       1.193097  495.070451   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                0.002548           0.121812            2       True   \n",
              "1                0.110458         106.030788            1       True   \n",
              "2                1.193097         495.070451            1       True   \n",
              "\n",
              "   fit_order  \n",
              "0          3  \n",
              "1          1  \n",
              "2          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b02d9b9d-4642-4096-ac35-fe76b8080387\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.988003</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>1.306103</td>\n",
              "      <td>601.223051</td>\n",
              "      <td>0.002548</td>\n",
              "      <td>0.121812</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.987198</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>0.110458</td>\n",
              "      <td>106.030788</td>\n",
              "      <td>0.110458</td>\n",
              "      <td>106.030788</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.984010</td>\n",
              "      <td>f1_weighted</td>\n",
              "      <td>1.193097</td>\n",
              "      <td>495.070451</td>\n",
              "      <td>1.193097</td>\n",
              "      <td>495.070451</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b02d9b9d-4642-4096-ac35-fe76b8080387')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b02d9b9d-4642-4096-ac35-fe76b8080387 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b02d9b9d-4642-4096-ac35-fe76b8080387');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-089a188c-b7d0-4a2a-8712-74346d5371db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-089a188c-b7d0-4a2a-8712-74346d5371db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-089a188c-b7d0-4a2a-8712-74346d5371db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_930966e9-927b-4041-b87b-fb1221c17674\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('leaderboard')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_930966e9-927b-4041-b87b-fb1221c17674 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('leaderboard');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "leaderboard",
              "summary": "{\n  \"name\": \"leaderboard\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"WeightedEnsemble_L2\",\n          \"NeuralNetFastAI\",\n          \"LightGBMXT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021117068570698457,\n        \"min\": 0.9840100876137018,\n        \"max\": 0.988003063438838,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.988003063438838,\n          0.9871982237946342,\n          0.9840100876137018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"f1_weighted\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6601066873479415,\n        \"min\": 0.1104576587677002,\n        \"max\": 1.3061025142669678,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.3061025142669678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260.7155573233511,\n        \"min\": 106.0307879447937,\n        \"max\": 601.2230508327484,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          601.2230508327484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6584274893833604,\n        \"min\": 0.002547740936279297,\n        \"max\": 1.1930971145629883,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.002547740936279297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260.6219245552497,\n        \"min\": 0.12181210517883301,\n        \"max\": 495.0704507827759,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.12181210517883301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "collapsed": true,
        "id": "evQa6ARWOJhX",
        "outputId": "59884f07-c0e7-4000-94c7-158ff882e7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "These features in provided data are not utilized by the predictor and will be ignored: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783]\n",
            "Computing feature importance via permutation shuffling for 0 features using 5000 rows with 5 shuffle sets...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"644 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 644 missing columns: ['12', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '113', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '449', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '762', '763', '764', '765', '766', '767', '768', '769', '770', '771', '772', '773', '774', '775'] | 0 available columns: []\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/features/generators/abstract.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;31m# therefore, try avoid copying by checking the expected features first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['12', '36', '37', '38', '39', '40', '41', '42', '43', '44',\\n       ...\\n       '766', '767', '768', '769', '770', '771', '772', '773', '774', '775'],\\n      dtype='object', length=644)] are in the [columns]\"",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b270dbefc23a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(self, data, model, features, feature_stage, subsample_size, time_limit, num_shuffle_sets, include_confidence_band, confidence_level, silent)\u001b[0m\n\u001b[1;32m   3415\u001b[0m             \u001b[0mnum_shuffle_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m         fi_df = self._learner.get_feature_importance(\n\u001b[0m\u001b[1;32m   3418\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mget_feature_importance\u001b[0;34m(self, model, X, y, features, feature_stage, subsample_size, silent, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeature_stage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"original\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m                 return trainer._get_feature_importance_raw(\n\u001b[0m\u001b[1;32m   1008\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_get_feature_importance_raw\u001b[0;34m(self, X, y, model, eval_metric, **kwargs)\u001b[0m\n\u001b[1;32m   3445\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAbstractModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m         \u001b[0mpredict_func_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3447\u001b[0;31m         return compute_permutation_feature_importance(\n\u001b[0m\u001b[1;32m   3448\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/utils/utils.py\u001b[0m in \u001b[0;36mcompute_permutation_feature_importance\u001b[0;34m(X, y, predict_func, eval_metric, features, subsample_size, num_shuffle_sets, predict_func_kwargs, transform_func, transform_func_kwargs, time_limit, silent, log_prefix, importance_as_list, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubsample\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshuffle_repeat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mtime_start_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtransform_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtransform_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtransform_func_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_func_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0mscore_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mtransform_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_generator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_generators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/features/generators/abstract.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mmissing_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0;34mf\"{len(missing_cols)} required columns are missing from the provided dataset to transform using {self.__class__.__name__}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;34mf\"{len(missing_cols)} missing columns: {missing_cols} | \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"644 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 644 missing columns: ['12', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '113', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bestmodel\n",
        "best_model_name = predictor.model_best  #\n",
        "print(f'best model name : {best_model_name}')\n",
        "# 테스트데이터\n",
        "predcitions = predictor.predict(test_data)\n",
        "predcitions, y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvoFHTfhORDr",
        "outputId": "784e1641-d82d-4279-f305-75f1eced8439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best model name : WeightedEnsemble_L2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0       7\n",
              " 1       2\n",
              " 2       1\n",
              " 3       0\n",
              " 4       4\n",
              "        ..\n",
              " 9995    2\n",
              " 9996    3\n",
              " 9997    4\n",
              " 9998    5\n",
              " 9999    6\n",
              " Name: target, Length: 10000, dtype: int64,\n",
              " tensor([7, 2, 1,  ..., 4, 5, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 성능이 2번째인 모델로 예측\n",
        "leaderboard.iloc[1]['model']\n",
        "predictions_2 = predictor.predict(test_data,model=leaderboard.iloc[1]['model'])\n",
        "predictions_2, y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wtZ9hf74Rnuf",
        "outputId": "6f681bdf-8499-4030-c22d-9de166ec3ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0       7\n",
              " 1       2\n",
              " 2       1\n",
              " 3       0\n",
              " 4       4\n",
              "        ..\n",
              " 9995    2\n",
              " 9996    3\n",
              " 9997    4\n",
              " 9998    5\n",
              " 9999    6\n",
              " Name: target, Length: 10000, dtype: int64,\n",
              " tensor([7, 2, 1,  ..., 4, 5, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "metrics = predictor.evaluate(test_data)\n",
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JFcM_A_OOnbF",
        "outputId": "27e16fdb-8156-40f2-c342-af57b741855e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1_weighted': 0.9830995276070795,\n",
              " 'accuracy': 0.9831,\n",
              " 'balanced_accuracy': 0.982962084803263,\n",
              " 'mcc': 0.9812157308479809}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 캘리포니아. 보스턴 집값 예측\n",
        "# 데이터셋 만들기 - automl\n",
        "# 분류모델인지 회귀인지는 디폴트로 auto 판단\n",
        "# 시간은 20분 설정  모델 리더보드를 통해 확인"
      ],
      "metadata": {
        "id": "mN8lyU5kVaaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 보스턴 집값 데이터 로드\n",
        "# from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "boston_X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "boston_y = raw_df.values[1::2, 2]\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "california =  fetch_california_housing()\n",
        "californa_X = california.data\n",
        "californa_y = california.target"
      ],
      "metadata": {
        "id": "UOh1ad87VqdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def makeDf(X,y):\n",
        "  df = pd.DataFrame(X)\n",
        "  df['target'] = y\n",
        "  return df\n",
        "\n",
        "boston_df = makeDf(boston_X,boston_y)\n",
        "californa_df = makeDf(californa_X,californa_y)\n",
        "\n",
        "boston_df_train,boston_df_test  =  train_test_split(boston_df,random_state=42)\n",
        "californa_df_train,californa_df_test =  train_test_split(californa_df,random_state=42)\n",
        "\n",
        "# TabularDataset\n",
        "boston_train = TabularDataset(boston_df_train)\n",
        "boston_test = TabularDataset(boston_df_test)\n",
        "\n",
        "californa_train = TabularDataset(californa_df_train)\n",
        "californa_test = TabularDataset(californa_df_test)"
      ],
      "metadata": {
        "id": "s5szL4odXR9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "df = scaler.fit_transform(boston_df.drop(columns=['target']))\n",
        "df = pd.DataFrame(df)\n",
        "df['target'] = boston_df['target']\n",
        "boston_train = df\n",
        "eval_metric = 'rmse'\n",
        "problem_type=\"regression\"\n",
        "excluded_model_types = [\n",
        "    'KNN','RF','XT','LR','NN'\n",
        "]\n",
        "time_limit = 60*10\n",
        "boston_predictor = TabularPredictor(\n",
        "    label='target',path='AutogluonModels/',eval_metric=eval_metric,problem_type=problem_type) \\\n",
        ".fit(boston_train,time_limit = time_limit\n",
        "     ,excluded_model_types=excluded_model_types\n",
        "     ,presets='best_quality'\n",
        "     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nsgggkogtk3V",
        "outputId": "d1315195-4324-4c59-c4b0-0dab8cb5470a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.72 GB / 12.67 GB (76.7%)\n",
            "Disk Space Avail:   61.19 GB / 107.72 GB (56.8%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      LightGBM_BAG_L2      -2.225729  -3.325685  root_mean_squared_error        3.361938       0.198943  71.377043                 0.292570                0.086037          35.682294            2       True          5\n",
            "1    LightGBMXT_BAG_L2      -2.446423  -3.396526  root_mean_squared_error        3.463976       0.277513  72.128047                 0.394608                0.164607          36.433298            2       True          4\n",
            "2    LightGBMXT_BAG_L1      -2.511361  -3.250957  root_mean_squared_error        3.069368       0.112906  35.694749                 3.069368                0.112906          35.694749            1       True          1\n",
            "3  WeightedEnsemble_L2      -2.511361  -3.250957  root_mean_squared_error        3.071712       0.113607  35.698772                 0.002344                0.000701           0.004023            2       True          3\n",
            "4  WeightedEnsemble_L3      -2.511361  -3.250957  root_mean_squared_error        3.071998       0.113503  35.698811                 0.002630                0.000597           0.004062            3       True          6\n",
            "5      LightGBM_BAG_L1      -2.532120  -3.304431  root_mean_squared_error        0.195559       0.055584  38.392508                 0.195559                0.055584          38.392508            1       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t190s\t = DyStack   runtime |\t410s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 410s\n",
            "AutoGluon will save models to \"/content/AutogluonModels\"\n",
            "Train Data Rows:    506\n",
            "Train Data Columns: 13\n",
            "Label Column:       target\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9749.34 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 12 | ['0', '1', '2', '4', '5', ...]\n",
            "\t\t('int', ['bool']) :  1 | ['3']\n",
            "\t0.1s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 273.36s of the 410.13s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-3.1097\t = Validation score   (-root_mean_squared_error)\n",
            "\t35.13s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 231.86s of the 368.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-3.155\t = Validation score   (-root_mean_squared_error)\n",
            "\t39.64s\t = Training   runtime\n",
            "\t0.52s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 185.14s of the 321.90s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-2.827\t = Validation score   (-root_mean_squared_error)\n",
            "\t70.84s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 107.61s of the 244.38s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t-3.7906\t = Validation score   (-root_mean_squared_error)\n",
            "\t49.57s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 52.86s of the 189.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-3.0609\t = Validation score   (-root_mean_squared_error)\n",
            "\t22.45s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 22.37s of the 159.14s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = RobustScaler()\n",
        "df = scaler.fit_transform(boston_test.drop(columns=['target']))\n",
        "df = pd.DataFrame(df)\n",
        "df['target'] = boston_test['target']\n",
        "boston_test = df\n",
        "boston_test.dropna(inplace=True)\n",
        "boston_predictor.evaluate(boston_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TQXaV47bw77o",
        "outputId": "c0b164fc-24cb-4531-f3e6-4e20e0a56756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'root_mean_squared_error': -10.016515335549649,\n",
              " 'mean_squared_error': -100.3305794673013,\n",
              " 'mean_absolute_error': -7.324061626858182,\n",
              " 'r2': -3.1340773148114964,\n",
              " 'pearsonr': 0.04058070473019103,\n",
              " 'median_absolute_error': -5.826446151733398}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습시간\n",
        "# 시간설정 (20분)\n",
        "time_limit = 60*20 # 1h : 60*60\n",
        "# gpu 사용불가 모델은 제외\n",
        "eval_metric = 'rmse'  # 평가방법  이진분류는 roc_auc  다중분류 roc_auc_ovo\n",
        "problem_type=\"regression\"\n",
        "excluded_model_types = [\n",
        "    'KNN','RF','XT','LR','NN'\n",
        "]\n",
        "# AutoGluon 학습\n",
        "boston_predictor = TabularPredictor(\n",
        "    label='target',path='AutogluonModels/',eval_metric=eval_metric,problem_type=problem_type) \\\n",
        ".fit(boston_train,time_limit = time_limit\n",
        "     ,excluded_model_types=excluded_model_types\n",
        "     ,presets='best_quality'\n",
        "     )\n",
        "californa_predictor = TabularPredictor(\n",
        "    label='target',path='AutogluonModels/',eval_metric=eval_metric,problem_type=problem_type) \\\n",
        ".fit(californa_train,time_limit = time_limit\n",
        "     ,excluded_model_types=excluded_model_types\n",
        "     ,presets='best_quality'\n",
        "     )\n",
        "# 평가방법"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OazuuDJBX5OP",
        "outputId": "263f0ab2-1f62-41c3-cc9d-d01bcdca96a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       8.08 GB / 12.67 GB (63.7%)\n",
            "Disk Space Avail:   61.40 GB / 107.72 GB (57.0%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 300s of the 1200s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ds_sub_fit/sub_fit_ho\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m(autoscaler +3m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[36m(_ray_fit pid=13864)\u001b[0m [1000]\tvalid_set's rmse: 2.75178\n",
            "\u001b[36m(_ray_fit pid=13864)\u001b[0m [2000]\tvalid_set's rmse: 2.70572\n",
            "\u001b[36m(_ray_fit pid=13998)\u001b[0m [1000]\tvalid_set's rmse: 4.89045\n",
            "\u001b[36m(_ray_fit pid=14094)\u001b[0m [1000]\tvalid_set's rmse: 3.12821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t-3.4301\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t38.85s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t0.05s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 53.24s of the 103.23s of remaining time.\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Beginning AutoGluon training ... Time limit = 300s\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Train Data Rows:    336\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Train Data Columns: 13\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Label Column:       target\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Problem Type:       regression\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tAvailable Memory:                    9918.75 MB\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\t('float', []) : 13 | ['0', '1', '2', '3', '4', ...]\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\t('float', [])     : 12 | ['0', '1', '2', '4', '5', ...]\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t\t('int', ['bool']) :  1 | ['3']\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t0.0s = Fit runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t13 features in original data used to generate 13 features in processed data.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Data preprocessing and feature engineering runtime = 0.03s ...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Excluded models: ['RF', 'XT', 'KNN'] (Specified by `excluded_model_types`)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m(autoscaler +3m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=14201)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 199.92s of the 299.94s of remaining time.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=14261)\u001b[0m [1000]\tvalid_set's rmse: 3.74988\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14362)\u001b[0m [1000]\tvalid_set's rmse: 2.75178\n",
            "\u001b[36m(_ray_fit pid=14362)\u001b[0m [2000]\tvalid_set's rmse: 2.70572\n",
            "\u001b[33m(autoscaler +4m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[36m(_ray_fit pid=14560)\u001b[0m [1000]\tvalid_set's rmse: 4.89045\n",
            "\u001b[36m(_ray_fit pid=14598)\u001b[0m [1000]\tvalid_set's rmse: 3.12821\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m [1000]\tvalid_set's rmse: 2.75057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t-3.4301\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t39.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t0.09s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 153.03s of the 253.05s of remaining time.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=14762)\u001b[0m [1000]\tvalid_set's rmse: 2.68933\n",
            "\u001b[33m(autoscaler +4m53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[36m(_ray_fit pid=14974)\u001b[0m [1000]\tvalid_set's rmse: 2.68933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t-3.6399\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t94.96s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t0.03s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 149.95s of the -11.12s of remaining time.\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t-3.4301\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m Excluded models: ['KNN', 'RF', 'XT'] (Specified by `excluded_model_types`)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 149.95s of the -11.39s of remaining time.\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t-3.4301\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m AutoGluon training complete, total runtime = 161.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 909.6 rows/s (42 batch size)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\u001b[36m(_dystack pid=13698)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 88.38s of the 188.40s of remaining time.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t-3.6399\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t50.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t0.12s\t = Validation runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m(autoscaler +5m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=15597)\u001b[0m \tRan out of time, early stopping on iteration 2144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m(autoscaler +6m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t-3.2826\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t59.79s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t0.02s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 20.26s of the 120.28s of remaining time.\n",
            "\u001b[36m(_ray_fit pid=15906)\u001b[0m \tRan out of time, early stopping on iteration 3552.\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m(autoscaler +6m48s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t-3.7689\t = Validation score   (-root_mean_squared_error)\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t48.99s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=14201)\u001b[0m \t0.13s\t = Validation runtime\n",
            "Warning: Exception encountered during DyStack sub-fit:\n",
            "\t[Errno 2] No such file or directory: '/content/AutogluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl'\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t259s\t = DyStack   runtime |\t941s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 941s\n",
            "AutoGluon will save models to \"/content/AutogluonModels\"\n",
            "Train Data Rows:    379\n",
            "Train Data Columns: 13\n",
            "Label Column:       target\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9297.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 12 | ['0', '1', '2', '4', '5', ...]\n",
            "\t\t('int', ['bool']) :  1 | ['3']\n",
            "\t0.1s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 627.01s of the 940.73s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-3.4237\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.29s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 589.00s of the 902.72s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-3.6416\t = Validation score   (-root_mean_squared_error)\n",
            "\t30.96s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 550.90s of the 864.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.2859\t = Validation score   (-root_mean_squared_error)\n",
            "\t145.2s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 401.04s of the 714.76s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-3.7095\t = Validation score   (-root_mean_squared_error)\n",
            "\t47.0s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 350.08s of the 663.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.7065\t = Validation score   (-root_mean_squared_error)\n",
            "\t21.29s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 321.99s of the 635.71s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.8958\t = Validation score   (-root_mean_squared_error)\n",
            "\t126.8s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 188.80s of the 502.52s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-3.7119\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.67s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 145.46s of the 459.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.3139\t = Validation score   (-root_mean_squared_error)\n",
            "\t50.44s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 89.50s of the 403.22s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.9312\t = Validation score   (-root_mean_squared_error)\n",
            "\t81.42s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3.72s of the 317.44s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-4.6128\t = Validation score   (-root_mean_squared_error)\n",
            "\t31.9s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 280.83s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.652, 'CatBoost_BAG_L1': 0.348}\n",
            "\t-2.734\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 280.79s of the 280.74s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.0429\t = Validation score   (-root_mean_squared_error)\n",
            "\t38.84s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 235.64s of the 235.59s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-3.0261\t = Validation score   (-root_mean_squared_error)\n",
            "\t34.6s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 194.84s of the 194.79s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-2.9926\t = Validation score   (-root_mean_squared_error)\n",
            "\t58.26s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 132.44s of the 132.39s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t-3.1897\t = Validation score   (-root_mean_squared_error)\n",
            "\t48.39s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 78.86s of the 78.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-3.4108\t = Validation score   (-root_mean_squared_error)\n",
            "\t24.64s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 48.72s of the 48.67s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.9657\t = Validation score   (-root_mean_squared_error)\n",
            "\t64.43s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.99s of the -20.33s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.542, 'CatBoost_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.208}\n",
            "\t-2.747\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 961.28s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 260.3 rows/s (48 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels\")\n",
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.37 GB / 12.67 GB (73.9%)\n",
            "Disk Space Avail:   61.28 GB / 107.72 GB (56.9%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 300s of the 1200s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L2      -0.431276  -0.453562  root_mean_squared_error       13.765811      11.651042  228.097800                 0.248755                0.293536          35.404865            2       True          5\n",
            "1  WeightedEnsemble_L3      -0.432453  -0.448096  root_mean_squared_error       13.855380      11.762110  263.297998                 0.003097                0.000974           0.026602            3       True          7\n",
            "2  WeightedEnsemble_L2      -0.433470  -0.448280  root_mean_squared_error        1.915262       2.412829  103.651871                 0.002434                0.001091           0.022270            2       True          4\n",
            "3      LightGBM_BAG_L2      -0.434188  -0.454198  root_mean_squared_error       13.603527      11.467600  227.866531                 0.086472                0.110094          35.173596            2       True          6\n",
            "4      LightGBM_BAG_L1      -0.436362  -0.453717  root_mean_squared_error        1.532625       2.288186   50.102943                 1.532625                2.288186          50.102943            1       True          2\n",
            "5      CatBoost_BAG_L1      -0.440607  -0.458455  root_mean_squared_error        0.380203       0.123552   53.526658                 0.380203                0.123552          53.526658            1       True          3\n",
            "6    LightGBMXT_BAG_L1      -0.449271  -0.473445  root_mean_squared_error       11.604228       8.945767   89.063335                11.604228                8.945767          89.063335            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t328s\t = DyStack   runtime |\t872s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 872s\n",
            "AutoGluon will save models to \"/content/AutogluonModels\"\n",
            "Train Data Rows:    15480\n",
            "Train Data Columns: 8\n",
            "Label Column:       target\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9930.72 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.94 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 8 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 8 | ['0', '1', '2', '3', '4', ...]\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.94 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 90 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 581.41s of the 872.31s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.4689\t = Validation score   (-root_mean_squared_error)\n",
            "\t95.81s\t = Training   runtime\n",
            "\t14.44s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 476.61s of the 767.51s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.4489\t = Validation score   (-root_mean_squared_error)\n",
            "\t55.45s\t = Training   runtime\n",
            "\t4.39s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 413.44s of the 704.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-0.4371\t = Validation score   (-root_mean_squared_error)\n",
            "\t344.31s\t = Training   runtime\n",
            "\t0.66s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 64.04s of the 354.94s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t-0.6341\t = Validation score   (-root_mean_squared_error)\n",
            "\t85.89s\t = Training   runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 264.79s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.733, 'LightGBM_BAG_L1': 0.267}\n",
            "\t-0.4353\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Excluded models: ['XT', 'RF', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 90 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 264.74s of the 264.70s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
            "\t-0.4425\t = Validation score   (-root_mean_squared_error)\n",
            "\t37.1s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 221.67s of the 221.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
            "\t-0.4386\t = Validation score   (-root_mean_squared_error)\n",
            "\t35.48s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 180.65s of the 180.61s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t-0.4379\t = Validation score   (-root_mean_squared_error)\n",
            "\t37.35s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 136.14s of the 136.10s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
            "\t-0.4344\t = Validation score   (-root_mean_squared_error)\n",
            "\t146.4s\t = Training   runtime\n",
            "\t0.62s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -16.86s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.5, 'CatBoost_BAG_L1': 0.227, 'LightGBM_BAG_L2': 0.182, 'LightGBM_BAG_L1': 0.045, 'CatBoost_BAG_L2': 0.045}\n",
            "\t-0.433\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 889.37s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 92.8 rows/s (1935 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boston_predictor.leaderboard(silent=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "collapsed": true,
        "id": "_Z7a62kaaDnp",
        "outputId": "3d006020-68ca-448a-eade-bf1671270c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        model  score_val              eval_metric  \\\n",
              "0         WeightedEnsemble_L2  -2.733966  root_mean_squared_error   \n",
              "1         WeightedEnsemble_L3  -2.746982  root_mean_squared_error   \n",
              "2       NeuralNetTorch_BAG_L1  -2.895835  root_mean_squared_error   \n",
              "3   NeuralNetTorch_r79_BAG_L1  -2.931230  root_mean_squared_error   \n",
              "4       NeuralNetTorch_BAG_L2  -2.965657  root_mean_squared_error   \n",
              "5             CatBoost_BAG_L2  -2.992598  root_mean_squared_error   \n",
              "6             LightGBM_BAG_L2  -3.026082  root_mean_squared_error   \n",
              "7           LightGBMXT_BAG_L2  -3.042896  root_mean_squared_error   \n",
              "8      NeuralNetFastAI_BAG_L2  -3.189674  root_mean_squared_error   \n",
              "9             CatBoost_BAG_L1  -3.285920  root_mean_squared_error   \n",
              "10       CatBoost_r177_BAG_L1  -3.313882  root_mean_squared_error   \n",
              "11             XGBoost_BAG_L2  -3.410801  root_mean_squared_error   \n",
              "12          LightGBMXT_BAG_L1  -3.423726  root_mean_squared_error   \n",
              "13            LightGBM_BAG_L1  -3.641612  root_mean_squared_error   \n",
              "14             XGBoost_BAG_L1  -3.706454  root_mean_squared_error   \n",
              "15     NeuralNetFastAI_BAG_L1  -3.709525  root_mean_squared_error   \n",
              "16       LightGBMLarge_BAG_L1  -3.711882  root_mean_squared_error   \n",
              "17       LightGBM_r131_BAG_L1  -4.612758  root_mean_squared_error   \n",
              "\n",
              "    pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
              "0        0.184994  272.016279                0.000674           0.016376   \n",
              "1        0.676790  465.464322                0.000580           0.020603   \n",
              "2        0.159194  126.800891                0.159194         126.800891   \n",
              "3        0.231888   81.423590                0.231888          81.423590   \n",
              "4        0.748815  437.014513                0.208993          64.434182   \n",
              "5        0.593412  430.845202                0.053590          58.264871   \n",
              "6        0.622619  407.178847                0.082798          34.598516   \n",
              "7        0.692327  411.419656                0.152506          38.839325   \n",
              "8        0.673627  420.968640                0.133806          48.388309   \n",
              "9        0.025126  145.199012                0.025126         145.199012   \n",
              "10       0.014876   50.435426                0.014876          50.435426   \n",
              "11       0.597415  397.216305                0.057593          24.635974   \n",
              "12       0.053269   32.290122                0.053269          32.290122   \n",
              "13       0.041367   30.963346                0.041367          30.963346   \n",
              "14       0.078241   21.287768                0.078241          21.287768   \n",
              "15       0.223992   47.002538                0.223992          47.002538   \n",
              "16       0.072792   36.668609                0.072792          36.668609   \n",
              "17       0.063233   31.897920                0.063233          31.897920   \n",
              "\n",
              "    stack_level  can_infer  fit_order  \n",
              "0             2       True         11  \n",
              "1             3       True         18  \n",
              "2             1       True          6  \n",
              "3             1       True          9  \n",
              "4             2       True         17  \n",
              "5             2       True         14  \n",
              "6             2       True         13  \n",
              "7             2       True         12  \n",
              "8             2       True         15  \n",
              "9             1       True          3  \n",
              "10            1       True          8  \n",
              "11            2       True         16  \n",
              "12            1       True          1  \n",
              "13            1       True          2  \n",
              "14            1       True          5  \n",
              "15            1       True          4  \n",
              "16            1       True          7  \n",
              "17            1       True         10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6603d024-2507-4891-bafe-886386d5cc49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-2.733966</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.184994</td>\n",
              "      <td>272.016279</td>\n",
              "      <td>0.000674</td>\n",
              "      <td>0.016376</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>-2.746982</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.676790</td>\n",
              "      <td>465.464322</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0.020603</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetTorch_BAG_L1</td>\n",
              "      <td>-2.895835</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.159194</td>\n",
              "      <td>126.800891</td>\n",
              "      <td>0.159194</td>\n",
              "      <td>126.800891</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
              "      <td>-2.931230</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.231888</td>\n",
              "      <td>81.423590</td>\n",
              "      <td>0.231888</td>\n",
              "      <td>81.423590</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NeuralNetTorch_BAG_L2</td>\n",
              "      <td>-2.965657</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.748815</td>\n",
              "      <td>437.014513</td>\n",
              "      <td>0.208993</td>\n",
              "      <td>64.434182</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>-2.992598</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.593412</td>\n",
              "      <td>430.845202</td>\n",
              "      <td>0.053590</td>\n",
              "      <td>58.264871</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>-3.026082</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.622619</td>\n",
              "      <td>407.178847</td>\n",
              "      <td>0.082798</td>\n",
              "      <td>34.598516</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>-3.042896</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.692327</td>\n",
              "      <td>411.419656</td>\n",
              "      <td>0.152506</td>\n",
              "      <td>38.839325</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2</td>\n",
              "      <td>-3.189674</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.673627</td>\n",
              "      <td>420.968640</td>\n",
              "      <td>0.133806</td>\n",
              "      <td>48.388309</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>-3.285920</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.025126</td>\n",
              "      <td>145.199012</td>\n",
              "      <td>0.025126</td>\n",
              "      <td>145.199012</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CatBoost_r177_BAG_L1</td>\n",
              "      <td>-3.313882</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.014876</td>\n",
              "      <td>50.435426</td>\n",
              "      <td>0.014876</td>\n",
              "      <td>50.435426</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>-3.410801</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.597415</td>\n",
              "      <td>397.216305</td>\n",
              "      <td>0.057593</td>\n",
              "      <td>24.635974</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>-3.423726</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.053269</td>\n",
              "      <td>32.290122</td>\n",
              "      <td>0.053269</td>\n",
              "      <td>32.290122</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>-3.641612</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.041367</td>\n",
              "      <td>30.963346</td>\n",
              "      <td>0.041367</td>\n",
              "      <td>30.963346</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>-3.706454</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.078241</td>\n",
              "      <td>21.287768</td>\n",
              "      <td>0.078241</td>\n",
              "      <td>21.287768</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>-3.709525</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.223992</td>\n",
              "      <td>47.002538</td>\n",
              "      <td>0.223992</td>\n",
              "      <td>47.002538</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LightGBMLarge_BAG_L1</td>\n",
              "      <td>-3.711882</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.072792</td>\n",
              "      <td>36.668609</td>\n",
              "      <td>0.072792</td>\n",
              "      <td>36.668609</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LightGBM_r131_BAG_L1</td>\n",
              "      <td>-4.612758</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.063233</td>\n",
              "      <td>31.897920</td>\n",
              "      <td>0.063233</td>\n",
              "      <td>31.897920</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6603d024-2507-4891-bafe-886386d5cc49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6603d024-2507-4891-bafe-886386d5cc49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6603d024-2507-4891-bafe-886386d5cc49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88e3d421-b82e-4914-9d06-1ac92779c08e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88e3d421-b82e-4914-9d06-1ac92779c08e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88e3d421-b82e-4914-9d06-1ac92779c08e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"boston_predictor\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"WeightedEnsemble_L2\",\n          \"WeightedEnsemble_L3\",\n          \"NeuralNetFastAI_BAG_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.46371449040721024,\n        \"min\": -4.6127575985906875,\n        \"max\": -2.7339661137425173,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          -2.7339661137425173,\n          -2.746981913548896,\n          -3.1896738722129063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"root_mean_squared_error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28630901685154303,\n        \"min\": 0.014876365661621094,\n        \"max\": 0.7488150596618652,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.18499398231506348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 182.92945733728612,\n        \"min\": 21.287768363952637,\n        \"max\": 465.46432185173035,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          272.0162789821625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07511286039837978,\n        \"min\": 0.0005803108215332031,\n        \"max\": 0.2318875789642334,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0006744861602783203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.73306981575413,\n        \"min\": 0.01637578010559082,\n        \"max\": 145.1990122795105,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.01637578010559082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 18,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = boston_predictor.predict(boston_test.drop(columns=['target']))\n",
        "mean_target = boston_test['target'].mean()\n",
        "mean_std = boston_test['target'].std()\n",
        "predictions_rescaled = predict*mean_std + mean_target\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(boston_df_test['target'],predictions_rescaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZYSsorBQe8tk",
        "outputId": "d2437a48-8347-450a-d352-622d9d7ed37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-4.3792101823255"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "californa_predictor.leaderboard(silent=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "collapsed": true,
        "id": "NZkYXJ7_diGo",
        "outputId": "1d7484b4-59ed-4f3f-a036-c3e108635a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    model  score_val              eval_metric  pred_time_val  \\\n",
              "0     WeightedEnsemble_L3  -0.433024  root_mean_squared_error      20.842119   \n",
              "1  NeuralNetFastAI_BAG_L2  -0.434436  root_mean_squared_error      20.680544   \n",
              "2     WeightedEnsemble_L2  -0.435252  root_mean_squared_error       5.050797   \n",
              "3         CatBoost_BAG_L1  -0.437094  root_mean_squared_error       0.658509   \n",
              "4         CatBoost_BAG_L2  -0.437902  root_mean_squared_error      20.125776   \n",
              "5         LightGBM_BAG_L2  -0.438613  root_mean_squared_error      20.165960   \n",
              "6       LightGBMXT_BAG_L2  -0.442495  root_mean_squared_error      20.373497   \n",
              "7         LightGBM_BAG_L1  -0.448945  root_mean_squared_error       4.391290   \n",
              "8       LightGBMXT_BAG_L1  -0.468873  root_mean_squared_error      14.443148   \n",
              "9  NeuralNetFastAI_BAG_L1  -0.634110  root_mean_squared_error       0.572476   \n",
              "\n",
              "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0  800.723066                0.000685           0.028901            3   \n",
              "1  727.866728                0.615121         146.401626            2   \n",
              "2  399.785899                0.000998           0.027942            2   \n",
              "3  344.306607                0.658509         344.306607            1   \n",
              "4  618.816718                0.060353          37.351616            2   \n",
              "5  616.940922                0.100537          35.475820            2   \n",
              "6  618.568178                0.308074          37.103076            2   \n",
              "7   55.451350                4.391290          55.451350            1   \n",
              "8   95.814415               14.443148          95.814415            1   \n",
              "9   85.892730                0.572476          85.892730            1   \n",
              "\n",
              "   can_infer  fit_order  \n",
              "0       True         10  \n",
              "1       True          9  \n",
              "2       True          5  \n",
              "3       True          3  \n",
              "4       True          8  \n",
              "5       True          7  \n",
              "6       True          6  \n",
              "7       True          2  \n",
              "8       True          1  \n",
              "9       True          4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d692dd18-e726-4d25-a373-0ee33851ee13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>-0.433024</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>20.842119</td>\n",
              "      <td>800.723066</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.028901</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2</td>\n",
              "      <td>-0.434436</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>20.680544</td>\n",
              "      <td>727.866728</td>\n",
              "      <td>0.615121</td>\n",
              "      <td>146.401626</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-0.435252</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>5.050797</td>\n",
              "      <td>399.785899</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.027942</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>-0.437094</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.658509</td>\n",
              "      <td>344.306607</td>\n",
              "      <td>0.658509</td>\n",
              "      <td>344.306607</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>-0.437902</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>20.125776</td>\n",
              "      <td>618.816718</td>\n",
              "      <td>0.060353</td>\n",
              "      <td>37.351616</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>-0.438613</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>20.165960</td>\n",
              "      <td>616.940922</td>\n",
              "      <td>0.100537</td>\n",
              "      <td>35.475820</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>-0.442495</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>20.373497</td>\n",
              "      <td>618.568178</td>\n",
              "      <td>0.308074</td>\n",
              "      <td>37.103076</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>-0.448945</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>4.391290</td>\n",
              "      <td>55.451350</td>\n",
              "      <td>4.391290</td>\n",
              "      <td>55.451350</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>-0.468873</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>14.443148</td>\n",
              "      <td>95.814415</td>\n",
              "      <td>14.443148</td>\n",
              "      <td>95.814415</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>-0.634110</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.572476</td>\n",
              "      <td>85.892730</td>\n",
              "      <td>0.572476</td>\n",
              "      <td>85.892730</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d692dd18-e726-4d25-a373-0ee33851ee13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d692dd18-e726-4d25-a373-0ee33851ee13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d692dd18-e726-4d25-a373-0ee33851ee13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f409fb50-163f-4bb3-bcd2-1441a4acea6d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f409fb50-163f-4bb3-bcd2-1441a4acea6d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f409fb50-163f-4bb3-bcd2-1441a4acea6d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"californa_predictor\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"LightGBMXT_BAG_L1\",\n          \"NeuralNetFastAI_BAG_L2\",\n          \"LightGBM_BAG_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06171106931948681,\n        \"min\": -0.6341101625251636,\n        \"max\": -0.43302357376550593,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.4688727809745989,\n          -0.4344363612007194,\n          -0.43861284160991565\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"root_mean_squared_error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.959148488765969,\n        \"min\": 0.5724763870239258,\n        \"max\": 20.842119216918945,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          14.443147659301758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 280.97801852162854,\n        \"min\": 55.45134997367859,\n        \"max\": 800.7230656147003,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          95.81441497802734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.526453793607082,\n        \"min\": 0.0006854534149169922,\n        \"max\": 14.443147659301758,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          14.443147659301758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101.89518663335598,\n        \"min\": 0.027942180633544922,\n        \"max\": 344.30660700798035,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          95.81441497802734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "californa_predictor.predict(californa_test), californa_test['target']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A4tMh1zqeKws",
        "outputId": "b7d93182-c9ea-4eb6-e3b1-6275e315fb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20046    0.558168\n",
              " 3024     0.848678\n",
              " 15663    5.063264\n",
              " 20484    2.537698\n",
              " 9814     2.589649\n",
              "            ...   \n",
              " 5363     4.865023\n",
              " 19755    0.670456\n",
              " 4885     1.286046\n",
              " 13043    2.774793\n",
              " 8583     4.231379\n",
              " Name: target, Length: 5160, dtype: float32,\n",
              " 20046    0.47700\n",
              " 3024     0.45800\n",
              " 15663    5.00001\n",
              " 20484    2.18600\n",
              " 9814     2.78000\n",
              "           ...   \n",
              " 5363     5.00001\n",
              " 19755    0.63200\n",
              " 4885     1.17700\n",
              " 13043    2.63100\n",
              " 8583     4.81500\n",
              " Name: target, Length: 5160, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "californa_predictor.evaluate(californa_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hjhPDYw8eZPk",
        "outputId": "50b62d64-19ef-4219-f0bc-13ecc042d675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'root_mean_squared_error': -0.42089142491560777,\n",
              " 'mean_squared_error': -0.17714959156749072,\n",
              " 'mean_absolute_error': -0.27173552918817645,\n",
              " 'r2': 0.8661221525690034,\n",
              " 'pearsonr': 0.9307890934939936,\n",
              " 'median_absolute_error': -0.17267675447463982}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boston DataSet"
      ],
      "metadata": {
        "id": "rdV_FJvZ8pbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "y = raw_df.values[1::2, 2]\n",
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "\n",
        "train_data, test_df = train_test_split(df,random_state=42)\n",
        "\n",
        "# 회귀는 기본적으로 -RMSE를 사용\n",
        "# 여러모델과 분류 및 기타 다른 용도로도 사용하기 때문에 높을수록 성능이 우수하도록 설계\n",
        "# 손실값은 - 로 표현\n",
        "predictor= TabularPredictor(label ='target').fit(train_data = train_data, verbosity = 2,presets='best_quality')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Jo0ixpn0s51o",
        "outputId": "20a6b62f-24dd-4bba-94be-8ed608c7a843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250416_045631\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.92 GB / 12.67 GB (78.3%)\n",
            "Disk Space Avail:   61.28 GB / 107.72 GB (56.9%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250416_045631/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                        model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0             CatBoost_BAG_L2      -3.098809  -3.260731  root_mean_squared_error        5.836534       0.970948  338.348130                 0.041864                0.039094          72.240062            2       True         19\n",
            "1        ExtraTreesMSE_BAG_L2      -3.262023  -3.178283  root_mean_squared_error        5.878512       1.063094  267.177613                 0.083842                0.131241           1.069546            2       True         20\n",
            "2             LightGBM_BAG_L2      -3.307133  -3.054743  root_mean_squared_error        5.853176       0.971174  300.135130                 0.058506                0.039321          34.027063            2       True         17\n",
            "3       NeuralNetTorch_BAG_L2      -3.349011  -3.115325  root_mean_squared_error        5.909577       1.479840  321.373640                 0.114907                0.547987          55.265573            2       True         23\n",
            "4        CatBoost_r177_BAG_L1      -3.367883  -3.254227  root_mean_squared_error        0.031942       0.018654   43.798787                 0.031942                0.018654          43.798787            1       True         12\n",
            "5         WeightedEnsemble_L3      -3.379241  -2.779265  root_mean_squared_error        5.856003       0.971893  300.211291                 0.002827                0.000719           0.076160            3       True         24\n",
            "6      NeuralNetFastAI_BAG_L2      -3.395377  -3.245490  root_mean_squared_error        5.895519       1.120826  315.922941                 0.100849                0.188973          49.814874            2       True         21\n",
            "7         WeightedEnsemble_L2      -3.405130  -2.788670  root_mean_squared_error        4.627123       0.341179  185.166337                 0.003927                0.000661           0.023360            2       True         15\n",
            "8             CatBoost_BAG_L1      -3.406735  -3.282635  root_mean_squared_error        0.389420       0.016139  128.182984                 0.389420                0.016139         128.182984            1       True          6\n",
            "9      RandomForestMSE_BAG_L2      -3.408495  -3.314837  root_mean_squared_error        5.884729       1.044807  269.065330                 0.090060                0.112954           2.957263            2       True         18\n",
            "10          LightGBMXT_BAG_L2      -3.457978  -3.264722  root_mean_squared_error        5.946643       1.004169  299.850916                 0.151973                0.072316          33.742849            2       True         16\n",
            "11             XGBoost_BAG_L2      -3.510066  -3.292582  root_mean_squared_error        5.909272       1.035109  291.631477                 0.114603                0.103256          25.523410            2       True         22\n",
            "12       ExtraTreesMSE_BAG_L1      -3.563041  -3.355327  root_mean_squared_error        0.078120       0.185639    0.944862                 0.078120                0.185639           0.944862            1       True          7\n",
            "13             XGBoost_BAG_L1      -3.749696  -3.764406  root_mean_squared_error        0.143075       0.063176   24.463320                 0.143075                0.063176          24.463320            1       True          9\n",
            "14      NeuralNetTorch_BAG_L1      -3.759141  -2.981670  root_mean_squared_error        0.100060       0.248041  103.480242                 0.100060                0.248041         103.480242            1       True         10\n",
            "15       LightGBM_r131_BAG_L1      -3.793282  -3.607821  root_mean_squared_error        0.223586       0.094233   34.346654                 0.223586                0.094233          34.346654            1       True         14\n",
            "16          LightGBMXT_BAG_L1      -3.800505  -3.430060  root_mean_squared_error        4.457086       0.060316   37.859849                 4.457086                0.060316          37.859849            1       True          3\n",
            "17  NeuralNetTorch_r79_BAG_L1      -3.816049  -3.015634  root_mean_squared_error        0.116777       0.143194   81.182409                 0.116777                0.143194          81.182409            1       True         13\n",
            "18     NeuralNetFastAI_BAG_L1      -3.864034  -3.768883  root_mean_squared_error        0.858529       0.124241   51.946754                 0.858529                0.124241          51.946754            1       True          8\n",
            "19     RandomForestMSE_BAG_L1      -3.900883  -3.581689  root_mean_squared_error        0.091750       0.218280    3.610153                 0.091750                0.218280           3.610153            1       True          5\n",
            "20            LightGBM_BAG_L1      -3.981755  -3.639899  root_mean_squared_error        0.045458       0.022259   33.203752                 0.045458                0.022259          33.203752            1       True          4\n",
            "21       LightGBMLarge_BAG_L1      -4.161396  -3.573563  root_mean_squared_error        0.321128       0.056595   41.536660                 0.321128                0.056595          41.536660            1       True         11\n",
            "22      KNeighborsDist_BAG_L1      -6.916252  -6.474056  root_mean_squared_error        0.034109       0.013507    0.004099                 0.034109                0.013507           0.004099            1       True          2\n",
            "23      KNeighborsUnif_BAG_L1      -7.157345  -6.757511  root_mean_squared_error        0.061063       0.016808    0.005559                 0.061063                0.016808           0.005559            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t944s\t = DyStack   runtime |\t2656s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 2656s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250416_045631\"\n",
            "Train Data Rows:    379\n",
            "Train Data Columns: 13\n",
            "Label Column:       target\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9929.29 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['0', '1', '2', '3', '4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 12 | ['0', '1', '2', '4', '5', ...]\n",
            "\t\t('int', ['bool']) :  1 | ['3']\n",
            "\t0.1s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1770.13s of the 2655.84s of remaining time.\n",
            "\t-6.828\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1770.04s of the 2655.75s of remaining time.\n",
            "\t-6.5775\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1770.01s of the 2655.72s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-3.4237\t = Validation score   (-root_mean_squared_error)\n",
            "\t34.55s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1729.82s of the 2615.53s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-3.6416\t = Validation score   (-root_mean_squared_error)\n",
            "\t32.08s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1692.90s of the 2578.61s of remaining time.\n",
            "\t-3.7284\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.39s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1691.18s of the 2576.89s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.2859\t = Validation score   (-root_mean_squared_error)\n",
            "\t266.72s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1417.86s of the 2303.57s of remaining time.\n",
            "\t-3.3809\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.99s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1416.49s of the 2302.20s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-3.7095\t = Validation score   (-root_mean_squared_error)\n",
            "\t48.39s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1362.41s of the 2248.12s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.7065\t = Validation score   (-root_mean_squared_error)\n",
            "\t23.38s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1332.75s of the 2218.46s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.8958\t = Validation score   (-root_mean_squared_error)\n",
            "\t128.63s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1199.68s of the 2085.39s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-3.7119\t = Validation score   (-root_mean_squared_error)\n",
            "\t40.47s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1154.49s of the 2040.20s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-3.3139\t = Validation score   (-root_mean_squared_error)\n",
            "\t58.11s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1092.17s of the 1977.88s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.9281\t = Validation score   (-root_mean_squared_error)\n",
            "\t98.13s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 987.72s of the 1873.43s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-3.6009\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.82s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 943.68s of the 1829.39s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-3.4028\t = Validation score   (-root_mean_squared_error)\n",
            "\t60.7s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 875.54s of the 1761.25s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
            "\t-3.5652\t = Validation score   (-root_mean_squared_error)\n",
            "\t233.43s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 636.92s of the 1522.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t-3.9076\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.36s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 587.82s of the 1473.53s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-3.2306\t = Validation score   (-root_mean_squared_error)\n",
            "\t100.92s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 480.33s of the 1366.04s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
            "\t-3.8499\t = Validation score   (-root_mean_squared_error)\n",
            "\t44.53s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 431.02s of the 1316.73s of remaining time.\n",
            "\t-3.3162\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.96s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 429.81s of the 1315.52s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t-3.2378\t = Validation score   (-root_mean_squared_error)\n",
            "\t121.72s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 304.34s of the 1190.05s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-3.2948\t = Validation score   (-root_mean_squared_error)\n",
            "\t67.83s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 231.80s of the 1117.51s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
            "\t-3.3857\t = Validation score   (-root_mean_squared_error)\n",
            "\t172.26s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 53.57s of the 939.28s of remaining time.\n",
            "\t-3.6115\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.16s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 52.15s of the 937.86s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-3.3634\t = Validation score   (-root_mean_squared_error)\n",
            "\t33.47s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 14.70s of the 900.41s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-3.1148\t = Validation score   (-root_mean_squared_error)\n",
            "\t54.87s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 838.64s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.542, 'CatBoost_r137_BAG_L1': 0.25, 'NeuralNetFastAI_r145_BAG_L1': 0.208}\n",
            "\t-2.6992\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 838.58s of the 838.33s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-2.9382\t = Validation score   (-root_mean_squared_error)\n",
            "\t40.94s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 790.44s of the 790.20s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t-2.7412\t = Validation score   (-root_mean_squared_error)\n",
            "\t36.04s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 749.67s of the 749.43s of remaining time.\n",
            "\t-2.8306\t = Validation score   (-root_mean_squared_error)\n",
            "\t2.77s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 746.62s of the 746.38s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
            "\t-3.0022\t = Validation score   (-root_mean_squared_error)\n",
            "\t66.26s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 675.88s of the 675.64s of remaining time.\n",
            "\t-2.9012\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.45s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 674.15s of the 673.91s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t-2.975\t = Validation score   (-root_mean_squared_error)\n",
            "\t49.95s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 620.20s of the 619.96s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
            "\t-3.0207\t = Validation score   (-root_mean_squared_error)\n",
            "\t27.36s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 584.97s of the 584.73s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.8224\t = Validation score   (-root_mean_squared_error)\n",
            "\t77.19s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 503.16s of the 502.92s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.30%)\n",
            "\t-2.8971\t = Validation score   (-root_mean_squared_error)\n",
            "\t107.84s\t = Training   runtime\n",
            "\t1.11s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 369.19s of the 368.95s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
            "\t-2.9569\t = Validation score   (-root_mean_squared_error)\n",
            "\t51.18s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 312.18s of the 311.94s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t-2.9376\t = Validation score   (-root_mean_squared_error)\n",
            "\t85.32s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 222.05s of the 221.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t-2.827\t = Validation score   (-root_mean_squared_error)\n",
            "\t40.88s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 175.75s of the 175.51s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t-2.9234\t = Validation score   (-root_mean_squared_error)\n",
            "\t59.18s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 112.12s of the 111.88s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.61%)\n",
            "\t-3.0862\t = Validation score   (-root_mean_squared_error)\n",
            "\t103.3s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 1.84s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.526, 'NeuralNetTorch_BAG_L2': 0.421, 'NeuralNetFastAI_r191_BAG_L2': 0.053}\n",
            "\t-2.5999\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2654.23s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 38.3 rows/s (48 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250416_045631\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          model    score_test  score_val  \\\n",
              "0         KNeighborsDist_BAG_L1 -5.614085e-07  -6.577513   \n",
              "1            XGBoost_r33_BAG_L1 -5.813374e-01  -3.849863   \n",
              "2            CatBoost_r9_BAG_L1 -6.673254e-01  -3.565220   \n",
              "3           CatBoost_r13_BAG_L1 -7.363171e-01  -3.385719   \n",
              "4                XGBoost_BAG_L1 -7.762401e-01  -3.706454   \n",
              "5          LightGBMLarge_BAG_L1 -8.534829e-01  -3.711882   \n",
              "6               CatBoost_BAG_L1 -8.743485e-01  -3.285920   \n",
              "7          CatBoost_r177_BAG_L1 -9.242222e-01  -3.313882   \n",
              "8          CatBoost_r137_BAG_L1 -1.069514e+00  -3.237796   \n",
              "9         ExtraTrees_r42_BAG_L1 -1.220821e+00  -3.316153   \n",
              "10         ExtraTreesMSE_BAG_L1 -1.248723e+00  -3.380886   \n",
              "11          WeightedEnsemble_L3 -1.283963e+00  -2.599906   \n",
              "12            LightGBMXT_BAG_L2 -1.314485e+00  -2.938185   \n",
              "13     RandomForest_r195_BAG_L1 -1.334612e+00  -3.611478   \n",
              "14              CatBoost_BAG_L2 -1.348990e+00  -3.002192   \n",
              "15       RandomForestMSE_BAG_L2 -1.350677e+00  -2.830589   \n",
              "16              LightGBM_BAG_L2 -1.375651e+00  -2.741190   \n",
              "17       RandomForestMSE_BAG_L1 -1.383482e+00  -3.728369   \n",
              "18         CatBoost_r177_BAG_L2 -1.391755e+00  -2.956868   \n",
              "19    NeuralNetTorch_r79_BAG_L2 -1.392641e+00  -2.937632   \n",
              "20         LightGBM_r131_BAG_L2 -1.395600e+00  -2.826952   \n",
              "21         LightGBMLarge_BAG_L2 -1.402709e+00  -2.897142   \n",
              "22        NeuralNetTorch_BAG_L2 -1.427870e+00  -2.822412   \n",
              "23           CatBoost_r9_BAG_L2 -1.431085e+00  -3.086243   \n",
              "24         ExtraTreesMSE_BAG_L2 -1.440744e+00  -2.901206   \n",
              "25         LightGBM_r188_BAG_L1 -1.447488e+00  -3.363394   \n",
              "26  NeuralNetFastAI_r191_BAG_L2 -1.470572e+00  -2.923406   \n",
              "27         LightGBM_r131_BAG_L1 -1.518600e+00  -3.600938   \n",
              "28       NeuralNetFastAI_BAG_L2 -1.561181e+00  -2.975000   \n",
              "29              LightGBM_BAG_L1 -1.585438e+00  -3.641612   \n",
              "30               XGBoost_BAG_L2 -1.671690e+00  -3.020679   \n",
              "31          WeightedEnsemble_L2 -1.797270e+00  -2.699152   \n",
              "32            LightGBMXT_BAG_L1 -1.929369e+00  -3.423726   \n",
              "33        NeuralNetTorch_BAG_L1 -2.109149e+00  -2.895835   \n",
              "34  NeuralNetFastAI_r145_BAG_L1 -2.286720e+00  -3.114751   \n",
              "35    NeuralNetTorch_r79_BAG_L1 -2.334841e+00  -2.928145   \n",
              "36  NeuralNetFastAI_r191_BAG_L1 -2.712538e+00  -3.402761   \n",
              "37  NeuralNetFastAI_r102_BAG_L1 -2.743220e+00  -3.294801   \n",
              "38    NeuralNetTorch_r22_BAG_L1 -2.763897e+00  -3.230574   \n",
              "39          LightGBM_r96_BAG_L1 -2.921761e+00  -3.907643   \n",
              "40       NeuralNetFastAI_BAG_L1 -2.941826e+00  -3.709525   \n",
              "41        KNeighborsUnif_BAG_L1 -5.428549e+00  -6.827997   \n",
              "\n",
              "                eval_metric  pred_time_test  pred_time_val    fit_time  \\\n",
              "0   root_mean_squared_error        0.021015       0.013638    0.005910   \n",
              "1   root_mean_squared_error        1.489797       0.261932   44.530389   \n",
              "2   root_mean_squared_error        0.496101       0.044414  233.428024   \n",
              "3   root_mean_squared_error        0.432711       0.024206  172.259996   \n",
              "4   root_mean_squared_error        0.338563       0.096619   23.378653   \n",
              "5   root_mean_squared_error        0.592724       0.060869   40.470383   \n",
              "6   root_mean_squared_error        0.595561       0.029414  266.716108   \n",
              "7   root_mean_squared_error        0.119963       0.014112   58.107791   \n",
              "8   root_mean_squared_error        0.124587       0.015640  121.723618   \n",
              "9   root_mean_squared_error        0.149321       0.195372    0.963074   \n",
              "10  root_mean_squared_error        0.255571       0.325630    0.992206   \n",
              "11  root_mean_squared_error        2.155828       1.622863  536.621618   \n",
              "12  root_mean_squared_error        2.452393       1.307280  405.139572   \n",
              "13  root_mean_squared_error        0.120828       0.213756    1.157424   \n",
              "14  root_mean_squared_error        1.498515       1.180667  430.461813   \n",
              "15  root_mean_squared_error        1.536195       1.346871  366.972642   \n",
              "16  root_mean_squared_error        1.780097       1.225824  400.233994   \n",
              "17  root_mean_squared_error        0.202017       0.267042    1.392886   \n",
              "18  root_mean_squared_error        1.467159       1.190170  415.381309   \n",
              "19  root_mean_squared_error        1.585671       1.309542  449.521833   \n",
              "20  root_mean_squared_error        1.944432       1.213398  405.082612   \n",
              "21  root_mean_squared_error        9.410929       2.248622  472.040378   \n",
              "22  root_mean_squared_error        1.618498       1.352595  441.384588   \n",
              "23  root_mean_squared_error        1.509209       1.206998  467.499227   \n",
              "24  root_mean_squared_error        1.610833       1.330935  365.652709   \n",
              "25  root_mean_squared_error        0.267344       0.157811   33.473389   \n",
              "26  root_mean_squared_error        1.620188       1.323292  423.375410   \n",
              "27  root_mean_squared_error        0.708555       0.087528   36.823365   \n",
              "28  root_mean_squared_error        1.663118       1.365884  414.147531   \n",
              "29  root_mean_squared_error        0.319747       0.026541   32.076434   \n",
              "30  root_mean_squared_error        1.657691       1.211861  391.560862   \n",
              "31  root_mean_squared_error        0.538642       0.463249  305.258810   \n",
              "32  root_mean_squared_error        0.592040       0.053407   34.548405   \n",
              "33  root_mean_squared_error        0.224893       0.184984  128.625676   \n",
              "34  root_mean_squared_error        0.186396       0.261952   54.870947   \n",
              "35  root_mean_squared_error        0.163512       0.160516   98.126449   \n",
              "36  root_mean_squared_error        0.375903       0.235071   60.698524   \n",
              "37  root_mean_squared_error        0.418383       0.221749   67.827288   \n",
              "38  root_mean_squared_error        0.196481       0.157992  100.923787   \n",
              "39  root_mean_squared_error        2.294956       0.242368   44.359431   \n",
              "40  root_mean_squared_error        0.478929       0.187045   48.391794   \n",
              "41  root_mean_squared_error        0.032870       0.056002    0.008040   \n",
              "\n",
              "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
              "0                  0.021015                0.013638           0.005910   \n",
              "1                  1.489797                0.261932          44.530389   \n",
              "2                  0.496101                0.044414         233.428024   \n",
              "3                  0.432711                0.024206         172.259996   \n",
              "4                  0.338563                0.096619          23.378653   \n",
              "5                  0.592724                0.060869          40.470383   \n",
              "6                  0.595561                0.029414         266.716108   \n",
              "7                  0.119963                0.014112          58.107791   \n",
              "8                  0.124587                0.015640         121.723618   \n",
              "9                  0.149321                0.195372           0.963074   \n",
              "10                 0.255571                0.325630           0.992206   \n",
              "11                 0.002939                0.000700           0.025008   \n",
              "12                 1.019446                0.167506          40.940881   \n",
              "13                 0.120828                0.213756           1.157424   \n",
              "14                 0.065568                0.040894          66.263122   \n",
              "15                 0.103248                0.207097           2.773951   \n",
              "16                 0.347150                0.086050          36.035303   \n",
              "17                 0.202017                0.267042           1.392886   \n",
              "18                 0.034213                0.050396          51.182618   \n",
              "19                 0.152724                0.169769          85.323143   \n",
              "20                 0.511485                0.073625          40.883921   \n",
              "21                 7.977982                1.108848         107.841687   \n",
              "22                 0.185551                0.212821          77.185897   \n",
              "23                 0.076263                0.067224         103.300536   \n",
              "24                 0.177886                0.191162           1.454018   \n",
              "25                 0.267344                0.157811          33.473389   \n",
              "26                 0.187241                0.183518          59.176719   \n",
              "27                 0.708555                0.087528          36.823365   \n",
              "28                 0.230172                0.226110          49.948840   \n",
              "29                 0.319747                0.026541          32.076434   \n",
              "30                 0.224745                0.072087          27.362171   \n",
              "31                 0.002766                0.000673           0.038569   \n",
              "32                 0.592040                0.053407          34.548405   \n",
              "33                 0.224893                0.184984         128.625676   \n",
              "34                 0.186396                0.261952          54.870947   \n",
              "35                 0.163512                0.160516          98.126449   \n",
              "36                 0.375903                0.235071          60.698524   \n",
              "37                 0.418383                0.221749          67.827288   \n",
              "38                 0.196481                0.157992         100.923787   \n",
              "39                 2.294956                0.242368          44.359431   \n",
              "40                 0.478929                0.187045          48.391794   \n",
              "41                 0.032870                0.056002           0.008040   \n",
              "\n",
              "    stack_level  can_infer  fit_order  \n",
              "0             1       True          2  \n",
              "1             1       True         19  \n",
              "2             1       True         16  \n",
              "3             1       True         23  \n",
              "4             1       True          9  \n",
              "5             1       True         11  \n",
              "6             1       True          6  \n",
              "7             1       True         12  \n",
              "8             1       True         21  \n",
              "9             1       True         20  \n",
              "10            1       True          7  \n",
              "11            3       True         42  \n",
              "12            2       True         28  \n",
              "13            1       True         24  \n",
              "14            2       True         31  \n",
              "15            2       True         30  \n",
              "16            2       True         29  \n",
              "17            1       True          5  \n",
              "18            2       True         37  \n",
              "19            2       True         38  \n",
              "20            2       True         39  \n",
              "21            2       True         36  \n",
              "22            2       True         35  \n",
              "23            2       True         41  \n",
              "24            2       True         32  \n",
              "25            1       True         25  \n",
              "26            2       True         40  \n",
              "27            1       True         14  \n",
              "28            2       True         33  \n",
              "29            1       True          4  \n",
              "30            2       True         34  \n",
              "31            2       True         27  \n",
              "32            1       True          3  \n",
              "33            1       True         10  \n",
              "34            1       True         26  \n",
              "35            1       True         13  \n",
              "36            1       True         15  \n",
              "37            1       True         22  \n",
              "38            1       True         18  \n",
              "39            1       True         17  \n",
              "40            1       True          8  \n",
              "41            1       True          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f7f204a-0e37-4347-bce1-446d8e4f6933\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsDist_BAG_L1</td>\n",
              "      <td>-5.614085e-07</td>\n",
              "      <td>-6.577513</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.021015</td>\n",
              "      <td>0.013638</td>\n",
              "      <td>0.005910</td>\n",
              "      <td>0.021015</td>\n",
              "      <td>0.013638</td>\n",
              "      <td>0.005910</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost_r33_BAG_L1</td>\n",
              "      <td>-5.813374e-01</td>\n",
              "      <td>-3.849863</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.489797</td>\n",
              "      <td>0.261932</td>\n",
              "      <td>44.530389</td>\n",
              "      <td>1.489797</td>\n",
              "      <td>0.261932</td>\n",
              "      <td>44.530389</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost_r9_BAG_L1</td>\n",
              "      <td>-6.673254e-01</td>\n",
              "      <td>-3.565220</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.496101</td>\n",
              "      <td>0.044414</td>\n",
              "      <td>233.428024</td>\n",
              "      <td>0.496101</td>\n",
              "      <td>0.044414</td>\n",
              "      <td>233.428024</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost_r13_BAG_L1</td>\n",
              "      <td>-7.363171e-01</td>\n",
              "      <td>-3.385719</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.432711</td>\n",
              "      <td>0.024206</td>\n",
              "      <td>172.259996</td>\n",
              "      <td>0.432711</td>\n",
              "      <td>0.024206</td>\n",
              "      <td>172.259996</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>-7.762401e-01</td>\n",
              "      <td>-3.706454</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.338563</td>\n",
              "      <td>0.096619</td>\n",
              "      <td>23.378653</td>\n",
              "      <td>0.338563</td>\n",
              "      <td>0.096619</td>\n",
              "      <td>23.378653</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBMLarge_BAG_L1</td>\n",
              "      <td>-8.534829e-01</td>\n",
              "      <td>-3.711882</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.592724</td>\n",
              "      <td>0.060869</td>\n",
              "      <td>40.470383</td>\n",
              "      <td>0.592724</td>\n",
              "      <td>0.060869</td>\n",
              "      <td>40.470383</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>-8.743485e-01</td>\n",
              "      <td>-3.285920</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.595561</td>\n",
              "      <td>0.029414</td>\n",
              "      <td>266.716108</td>\n",
              "      <td>0.595561</td>\n",
              "      <td>0.029414</td>\n",
              "      <td>266.716108</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CatBoost_r177_BAG_L1</td>\n",
              "      <td>-9.242222e-01</td>\n",
              "      <td>-3.313882</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.119963</td>\n",
              "      <td>0.014112</td>\n",
              "      <td>58.107791</td>\n",
              "      <td>0.119963</td>\n",
              "      <td>0.014112</td>\n",
              "      <td>58.107791</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CatBoost_r137_BAG_L1</td>\n",
              "      <td>-1.069514e+00</td>\n",
              "      <td>-3.237796</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.124587</td>\n",
              "      <td>0.015640</td>\n",
              "      <td>121.723618</td>\n",
              "      <td>0.124587</td>\n",
              "      <td>0.015640</td>\n",
              "      <td>121.723618</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTrees_r42_BAG_L1</td>\n",
              "      <td>-1.220821e+00</td>\n",
              "      <td>-3.316153</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.149321</td>\n",
              "      <td>0.195372</td>\n",
              "      <td>0.963074</td>\n",
              "      <td>0.149321</td>\n",
              "      <td>0.195372</td>\n",
              "      <td>0.963074</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesMSE_BAG_L1</td>\n",
              "      <td>-1.248723e+00</td>\n",
              "      <td>-3.380886</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.255571</td>\n",
              "      <td>0.325630</td>\n",
              "      <td>0.992206</td>\n",
              "      <td>0.255571</td>\n",
              "      <td>0.325630</td>\n",
              "      <td>0.992206</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>-1.283963e+00</td>\n",
              "      <td>-2.599906</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.155828</td>\n",
              "      <td>1.622863</td>\n",
              "      <td>536.621618</td>\n",
              "      <td>0.002939</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.025008</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>-1.314485e+00</td>\n",
              "      <td>-2.938185</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.452393</td>\n",
              "      <td>1.307280</td>\n",
              "      <td>405.139572</td>\n",
              "      <td>1.019446</td>\n",
              "      <td>0.167506</td>\n",
              "      <td>40.940881</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RandomForest_r195_BAG_L1</td>\n",
              "      <td>-1.334612e+00</td>\n",
              "      <td>-3.611478</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.120828</td>\n",
              "      <td>0.213756</td>\n",
              "      <td>1.157424</td>\n",
              "      <td>0.120828</td>\n",
              "      <td>0.213756</td>\n",
              "      <td>1.157424</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>-1.348990e+00</td>\n",
              "      <td>-3.002192</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.498515</td>\n",
              "      <td>1.180667</td>\n",
              "      <td>430.461813</td>\n",
              "      <td>0.065568</td>\n",
              "      <td>0.040894</td>\n",
              "      <td>66.263122</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RandomForestMSE_BAG_L2</td>\n",
              "      <td>-1.350677e+00</td>\n",
              "      <td>-2.830589</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.536195</td>\n",
              "      <td>1.346871</td>\n",
              "      <td>366.972642</td>\n",
              "      <td>0.103248</td>\n",
              "      <td>0.207097</td>\n",
              "      <td>2.773951</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>-1.375651e+00</td>\n",
              "      <td>-2.741190</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.780097</td>\n",
              "      <td>1.225824</td>\n",
              "      <td>400.233994</td>\n",
              "      <td>0.347150</td>\n",
              "      <td>0.086050</td>\n",
              "      <td>36.035303</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RandomForestMSE_BAG_L1</td>\n",
              "      <td>-1.383482e+00</td>\n",
              "      <td>-3.728369</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.202017</td>\n",
              "      <td>0.267042</td>\n",
              "      <td>1.392886</td>\n",
              "      <td>0.202017</td>\n",
              "      <td>0.267042</td>\n",
              "      <td>1.392886</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CatBoost_r177_BAG_L2</td>\n",
              "      <td>-1.391755e+00</td>\n",
              "      <td>-2.956868</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.467159</td>\n",
              "      <td>1.190170</td>\n",
              "      <td>415.381309</td>\n",
              "      <td>0.034213</td>\n",
              "      <td>0.050396</td>\n",
              "      <td>51.182618</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L2</td>\n",
              "      <td>-1.392641e+00</td>\n",
              "      <td>-2.937632</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.585671</td>\n",
              "      <td>1.309542</td>\n",
              "      <td>449.521833</td>\n",
              "      <td>0.152724</td>\n",
              "      <td>0.169769</td>\n",
              "      <td>85.323143</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>LightGBM_r131_BAG_L2</td>\n",
              "      <td>-1.395600e+00</td>\n",
              "      <td>-2.826952</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.944432</td>\n",
              "      <td>1.213398</td>\n",
              "      <td>405.082612</td>\n",
              "      <td>0.511485</td>\n",
              "      <td>0.073625</td>\n",
              "      <td>40.883921</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>LightGBMLarge_BAG_L2</td>\n",
              "      <td>-1.402709e+00</td>\n",
              "      <td>-2.897142</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>9.410929</td>\n",
              "      <td>2.248622</td>\n",
              "      <td>472.040378</td>\n",
              "      <td>7.977982</td>\n",
              "      <td>1.108848</td>\n",
              "      <td>107.841687</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NeuralNetTorch_BAG_L2</td>\n",
              "      <td>-1.427870e+00</td>\n",
              "      <td>-2.822412</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.618498</td>\n",
              "      <td>1.352595</td>\n",
              "      <td>441.384588</td>\n",
              "      <td>0.185551</td>\n",
              "      <td>0.212821</td>\n",
              "      <td>77.185897</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>CatBoost_r9_BAG_L2</td>\n",
              "      <td>-1.431085e+00</td>\n",
              "      <td>-3.086243</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.509209</td>\n",
              "      <td>1.206998</td>\n",
              "      <td>467.499227</td>\n",
              "      <td>0.076263</td>\n",
              "      <td>0.067224</td>\n",
              "      <td>103.300536</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ExtraTreesMSE_BAG_L2</td>\n",
              "      <td>-1.440744e+00</td>\n",
              "      <td>-2.901206</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.610833</td>\n",
              "      <td>1.330935</td>\n",
              "      <td>365.652709</td>\n",
              "      <td>0.177886</td>\n",
              "      <td>0.191162</td>\n",
              "      <td>1.454018</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>LightGBM_r188_BAG_L1</td>\n",
              "      <td>-1.447488e+00</td>\n",
              "      <td>-3.363394</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.157811</td>\n",
              "      <td>33.473389</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.157811</td>\n",
              "      <td>33.473389</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NeuralNetFastAI_r191_BAG_L2</td>\n",
              "      <td>-1.470572e+00</td>\n",
              "      <td>-2.923406</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.620188</td>\n",
              "      <td>1.323292</td>\n",
              "      <td>423.375410</td>\n",
              "      <td>0.187241</td>\n",
              "      <td>0.183518</td>\n",
              "      <td>59.176719</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>LightGBM_r131_BAG_L1</td>\n",
              "      <td>-1.518600e+00</td>\n",
              "      <td>-3.600938</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.708555</td>\n",
              "      <td>0.087528</td>\n",
              "      <td>36.823365</td>\n",
              "      <td>0.708555</td>\n",
              "      <td>0.087528</td>\n",
              "      <td>36.823365</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2</td>\n",
              "      <td>-1.561181e+00</td>\n",
              "      <td>-2.975000</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.663118</td>\n",
              "      <td>1.365884</td>\n",
              "      <td>414.147531</td>\n",
              "      <td>0.230172</td>\n",
              "      <td>0.226110</td>\n",
              "      <td>49.948840</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>-1.585438e+00</td>\n",
              "      <td>-3.641612</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.319747</td>\n",
              "      <td>0.026541</td>\n",
              "      <td>32.076434</td>\n",
              "      <td>0.319747</td>\n",
              "      <td>0.026541</td>\n",
              "      <td>32.076434</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>-1.671690e+00</td>\n",
              "      <td>-3.020679</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.657691</td>\n",
              "      <td>1.211861</td>\n",
              "      <td>391.560862</td>\n",
              "      <td>0.224745</td>\n",
              "      <td>0.072087</td>\n",
              "      <td>27.362171</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-1.797270e+00</td>\n",
              "      <td>-2.699152</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.538642</td>\n",
              "      <td>0.463249</td>\n",
              "      <td>305.258810</td>\n",
              "      <td>0.002766</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>0.038569</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>-1.929369e+00</td>\n",
              "      <td>-3.423726</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.592040</td>\n",
              "      <td>0.053407</td>\n",
              "      <td>34.548405</td>\n",
              "      <td>0.592040</td>\n",
              "      <td>0.053407</td>\n",
              "      <td>34.548405</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>NeuralNetTorch_BAG_L1</td>\n",
              "      <td>-2.109149e+00</td>\n",
              "      <td>-2.895835</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.224893</td>\n",
              "      <td>0.184984</td>\n",
              "      <td>128.625676</td>\n",
              "      <td>0.224893</td>\n",
              "      <td>0.184984</td>\n",
              "      <td>128.625676</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>NeuralNetFastAI_r145_BAG_L1</td>\n",
              "      <td>-2.286720e+00</td>\n",
              "      <td>-3.114751</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.186396</td>\n",
              "      <td>0.261952</td>\n",
              "      <td>54.870947</td>\n",
              "      <td>0.186396</td>\n",
              "      <td>0.261952</td>\n",
              "      <td>54.870947</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
              "      <td>-2.334841e+00</td>\n",
              "      <td>-2.928145</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.163512</td>\n",
              "      <td>0.160516</td>\n",
              "      <td>98.126449</td>\n",
              "      <td>0.163512</td>\n",
              "      <td>0.160516</td>\n",
              "      <td>98.126449</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
              "      <td>-2.712538e+00</td>\n",
              "      <td>-3.402761</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.375903</td>\n",
              "      <td>0.235071</td>\n",
              "      <td>60.698524</td>\n",
              "      <td>0.375903</td>\n",
              "      <td>0.235071</td>\n",
              "      <td>60.698524</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NeuralNetFastAI_r102_BAG_L1</td>\n",
              "      <td>-2.743220e+00</td>\n",
              "      <td>-3.294801</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.418383</td>\n",
              "      <td>0.221749</td>\n",
              "      <td>67.827288</td>\n",
              "      <td>0.418383</td>\n",
              "      <td>0.221749</td>\n",
              "      <td>67.827288</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>NeuralNetTorch_r22_BAG_L1</td>\n",
              "      <td>-2.763897e+00</td>\n",
              "      <td>-3.230574</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.196481</td>\n",
              "      <td>0.157992</td>\n",
              "      <td>100.923787</td>\n",
              "      <td>0.196481</td>\n",
              "      <td>0.157992</td>\n",
              "      <td>100.923787</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>LightGBM_r96_BAG_L1</td>\n",
              "      <td>-2.921761e+00</td>\n",
              "      <td>-3.907643</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.294956</td>\n",
              "      <td>0.242368</td>\n",
              "      <td>44.359431</td>\n",
              "      <td>2.294956</td>\n",
              "      <td>0.242368</td>\n",
              "      <td>44.359431</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>-2.941826e+00</td>\n",
              "      <td>-3.709525</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.478929</td>\n",
              "      <td>0.187045</td>\n",
              "      <td>48.391794</td>\n",
              "      <td>0.478929</td>\n",
              "      <td>0.187045</td>\n",
              "      <td>48.391794</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>KNeighborsUnif_BAG_L1</td>\n",
              "      <td>-5.428549e+00</td>\n",
              "      <td>-6.827997</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.032870</td>\n",
              "      <td>0.056002</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.032870</td>\n",
              "      <td>0.056002</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f7f204a-0e37-4347-bce1-446d8e4f6933')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f7f204a-0e37-4347-bce1-446d8e4f6933 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f7f204a-0e37-4347-bce1-446d8e4f6933');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cdaf0f7a-4ea7-4bad-9b4c-32590d6d5be5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdaf0f7a-4ea7-4bad-9b4c-32590d6d5be5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cdaf0f7a-4ea7-4bad-9b4c-32590d6d5be5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 42,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"LightGBM_r188_BAG_L1\",\n          \"RandomForest_r195_BAG_L1\",\n          \"CatBoost_r137_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.887321186898289,\n        \"min\": -5.428548800165754,\n        \"max\": -5.614085050175813e-07,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          -1.4474876687986884,\n          -1.334611515012887,\n          -1.0695141523056944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8264419835714897,\n        \"min\": -6.827997397640703,\n        \"max\": -2.5999064398741223,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          -3.3633944792217023,\n          -3.6114780245451317,\n          -3.2377960760951967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"root_mean_squared_error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5081913627841688,\n        \"min\": 0.021014690399169922,\n        \"max\": 9.410928964614868,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.26734447479248047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6153001286581496,\n        \"min\": 0.013638019561767578,\n        \"max\": 2.248621702194214,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.15781140327453613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184.38874712897487,\n        \"min\": 0.005910396575927734,\n        \"max\": 536.6216175556183,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          33.47338891029358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2484658830241808,\n        \"min\": 0.0027658939361572266,\n        \"max\": 7.97798228263855,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.26734447479248047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17591622089155107,\n        \"min\": 0.0006725788116455078,\n        \"max\": 1.1088478565216064,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.15781140327453613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.40892448718246,\n        \"min\": 0.005910396575927734,\n        \"max\": 266.7161078453064,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          33.47338891029358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 42,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard(train_data, silent=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "QhDntWq58tMm",
        "outputId": "421bad51-701e-403f-faf1-e669e7eb153e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          model    score_test  score_val  \\\n",
              "0         KNeighborsDist_BAG_L1 -5.614085e-07  -6.577513   \n",
              "1            XGBoost_r33_BAG_L1 -5.813374e-01  -3.849863   \n",
              "2            CatBoost_r9_BAG_L1 -6.673254e-01  -3.565220   \n",
              "3           CatBoost_r13_BAG_L1 -7.363171e-01  -3.385719   \n",
              "4                XGBoost_BAG_L1 -7.762401e-01  -3.706454   \n",
              "5          LightGBMLarge_BAG_L1 -8.534829e-01  -3.711882   \n",
              "6               CatBoost_BAG_L1 -8.743485e-01  -3.285920   \n",
              "7          CatBoost_r177_BAG_L1 -9.242222e-01  -3.313882   \n",
              "8          CatBoost_r137_BAG_L1 -1.069514e+00  -3.237796   \n",
              "9         ExtraTrees_r42_BAG_L1 -1.220821e+00  -3.316153   \n",
              "10         ExtraTreesMSE_BAG_L1 -1.248723e+00  -3.380886   \n",
              "11          WeightedEnsemble_L3 -1.283963e+00  -2.599906   \n",
              "12            LightGBMXT_BAG_L2 -1.314485e+00  -2.938185   \n",
              "13     RandomForest_r195_BAG_L1 -1.334612e+00  -3.611478   \n",
              "14              CatBoost_BAG_L2 -1.348990e+00  -3.002192   \n",
              "15       RandomForestMSE_BAG_L2 -1.350677e+00  -2.830589   \n",
              "16              LightGBM_BAG_L2 -1.375651e+00  -2.741190   \n",
              "17       RandomForestMSE_BAG_L1 -1.383482e+00  -3.728369   \n",
              "18         CatBoost_r177_BAG_L2 -1.391755e+00  -2.956868   \n",
              "19    NeuralNetTorch_r79_BAG_L2 -1.392641e+00  -2.937632   \n",
              "20         LightGBM_r131_BAG_L2 -1.395600e+00  -2.826952   \n",
              "21         LightGBMLarge_BAG_L2 -1.402709e+00  -2.897142   \n",
              "22        NeuralNetTorch_BAG_L2 -1.427870e+00  -2.822412   \n",
              "23           CatBoost_r9_BAG_L2 -1.431085e+00  -3.086243   \n",
              "24         ExtraTreesMSE_BAG_L2 -1.440744e+00  -2.901206   \n",
              "25         LightGBM_r188_BAG_L1 -1.447488e+00  -3.363394   \n",
              "26  NeuralNetFastAI_r191_BAG_L2 -1.470572e+00  -2.923406   \n",
              "27         LightGBM_r131_BAG_L1 -1.518600e+00  -3.600938   \n",
              "28       NeuralNetFastAI_BAG_L2 -1.561181e+00  -2.975000   \n",
              "29              LightGBM_BAG_L1 -1.585438e+00  -3.641612   \n",
              "30               XGBoost_BAG_L2 -1.671690e+00  -3.020679   \n",
              "31          WeightedEnsemble_L2 -1.797270e+00  -2.699152   \n",
              "32            LightGBMXT_BAG_L1 -1.929369e+00  -3.423726   \n",
              "33        NeuralNetTorch_BAG_L1 -2.109149e+00  -2.895835   \n",
              "34  NeuralNetFastAI_r145_BAG_L1 -2.286720e+00  -3.114751   \n",
              "35    NeuralNetTorch_r79_BAG_L1 -2.334841e+00  -2.928145   \n",
              "36  NeuralNetFastAI_r191_BAG_L1 -2.712538e+00  -3.402761   \n",
              "37  NeuralNetFastAI_r102_BAG_L1 -2.743220e+00  -3.294801   \n",
              "38    NeuralNetTorch_r22_BAG_L1 -2.763897e+00  -3.230574   \n",
              "39          LightGBM_r96_BAG_L1 -2.921761e+00  -3.907643   \n",
              "40       NeuralNetFastAI_BAG_L1 -2.941826e+00  -3.709525   \n",
              "41        KNeighborsUnif_BAG_L1 -5.428549e+00  -6.827997   \n",
              "\n",
              "                eval_metric  pred_time_test  pred_time_val    fit_time  \\\n",
              "0   root_mean_squared_error        0.014902       0.013638    0.005910   \n",
              "1   root_mean_squared_error        0.995560       0.261932   44.530389   \n",
              "2   root_mean_squared_error        0.687863       0.044414  233.428024   \n",
              "3   root_mean_squared_error        0.114889       0.024206  172.259996   \n",
              "4   root_mean_squared_error        0.541543       0.096619   23.378653   \n",
              "5   root_mean_squared_error        1.308167       0.060869   40.470383   \n",
              "6   root_mean_squared_error        0.350428       0.029414  266.716108   \n",
              "7   root_mean_squared_error        0.217206       0.014112   58.107791   \n",
              "8   root_mean_squared_error        0.096952       0.015640  121.723618   \n",
              "9   root_mean_squared_error        0.106155       0.195372    0.963074   \n",
              "10  root_mean_squared_error        0.259670       0.325630    0.992206   \n",
              "11  root_mean_squared_error        2.556818       1.622863  536.621618   \n",
              "12  root_mean_squared_error        2.948161       1.307280  405.139572   \n",
              "13  root_mean_squared_error        0.108000       0.213756    1.157424   \n",
              "14  root_mean_squared_error        1.969364       1.180667  430.461813   \n",
              "15  root_mean_squared_error        2.013429       1.346871  366.972642   \n",
              "16  root_mean_squared_error        2.178673       1.225824  400.233994   \n",
              "17  root_mean_squared_error        0.175035       0.267042    1.392886   \n",
              "18  root_mean_squared_error        1.934484       1.190170  415.381309   \n",
              "19  root_mean_squared_error        2.047570       1.309542  449.521833   \n",
              "20  root_mean_squared_error        2.476198       1.213398  405.082612   \n",
              "21  root_mean_squared_error        9.732880       2.248622  472.040378   \n",
              "22  root_mean_squared_error        2.081068       1.352595  441.384588   \n",
              "23  root_mean_squared_error        1.989565       1.206998  467.499227   \n",
              "24  root_mean_squared_error        2.017591       1.330935  365.652709   \n",
              "25  root_mean_squared_error        0.343110       0.157811   33.473389   \n",
              "26  root_mean_squared_error        2.087459       1.323292  423.375410   \n",
              "27  root_mean_squared_error        2.284922       0.087528   36.823365   \n",
              "28  root_mean_squared_error        2.324497       1.365884  414.147531   \n",
              "29  root_mean_squared_error        0.268034       0.026541   32.076434   \n",
              "30  root_mean_squared_error        2.119350       1.211861  391.560862   \n",
              "31  root_mean_squared_error        0.788918       0.463249  305.258810   \n",
              "32  root_mean_squared_error        0.511256       0.053407   34.548405   \n",
              "33  root_mean_squared_error        0.481119       0.184984  128.625676   \n",
              "34  root_mean_squared_error        0.204799       0.261952   54.870947   \n",
              "35  root_mean_squared_error        0.624557       0.160516   98.126449   \n",
              "36  root_mean_squared_error        0.651509       0.235071   60.698524   \n",
              "37  root_mean_squared_error        0.384085       0.221749   67.827288   \n",
              "38  root_mean_squared_error        0.566414       0.157992  100.923787   \n",
              "39  root_mean_squared_error        4.124207       0.242368   44.359431   \n",
              "40  root_mean_squared_error        0.335595       0.187045   48.391794   \n",
              "41  root_mean_squared_error        0.015244       0.056002    0.008040   \n",
              "\n",
              "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
              "0                  0.014902                0.013638           0.005910   \n",
              "1                  0.995560                0.261932          44.530389   \n",
              "2                  0.687863                0.044414         233.428024   \n",
              "3                  0.114889                0.024206         172.259996   \n",
              "4                  0.541543                0.096619          23.378653   \n",
              "5                  1.308167                0.060869          40.470383   \n",
              "6                  0.350428                0.029414         266.716108   \n",
              "7                  0.217206                0.014112          58.107791   \n",
              "8                  0.096952                0.015640         121.723618   \n",
              "9                  0.106155                0.195372           0.963074   \n",
              "10                 0.259670                0.325630           0.992206   \n",
              "11                 0.002779                0.000700           0.025008   \n",
              "12                 1.051580                0.167506          40.940881   \n",
              "13                 0.108000                0.213756           1.157424   \n",
              "14                 0.072783                0.040894          66.263122   \n",
              "15                 0.116849                0.207097           2.773951   \n",
              "16                 0.282093                0.086050          36.035303   \n",
              "17                 0.175035                0.267042           1.392886   \n",
              "18                 0.037904                0.050396          51.182618   \n",
              "19                 0.150990                0.169769          85.323143   \n",
              "20                 0.579618                0.073625          40.883921   \n",
              "21                 7.836300                1.108848         107.841687   \n",
              "22                 0.184487                0.212821          77.185897   \n",
              "23                 0.092985                0.067224         103.300536   \n",
              "24                 0.121010                0.191162           1.454018   \n",
              "25                 0.343110                0.157811          33.473389   \n",
              "26                 0.190879                0.183518          59.176719   \n",
              "27                 2.284922                0.087528          36.823365   \n",
              "28                 0.427917                0.226110          49.948840   \n",
              "29                 0.268034                0.026541          32.076434   \n",
              "30                 0.222770                0.072087          27.362171   \n",
              "31                 0.006048                0.000673           0.038569   \n",
              "32                 0.511256                0.053407          34.548405   \n",
              "33                 0.481119                0.184984         128.625676   \n",
              "34                 0.204799                0.261952          54.870947   \n",
              "35                 0.624557                0.160516          98.126449   \n",
              "36                 0.651509                0.235071          60.698524   \n",
              "37                 0.384085                0.221749          67.827288   \n",
              "38                 0.566414                0.157992         100.923787   \n",
              "39                 4.124207                0.242368          44.359431   \n",
              "40                 0.335595                0.187045          48.391794   \n",
              "41                 0.015244                0.056002           0.008040   \n",
              "\n",
              "    stack_level  can_infer  fit_order  \n",
              "0             1       True          2  \n",
              "1             1       True         19  \n",
              "2             1       True         16  \n",
              "3             1       True         23  \n",
              "4             1       True          9  \n",
              "5             1       True         11  \n",
              "6             1       True          6  \n",
              "7             1       True         12  \n",
              "8             1       True         21  \n",
              "9             1       True         20  \n",
              "10            1       True          7  \n",
              "11            3       True         42  \n",
              "12            2       True         28  \n",
              "13            1       True         24  \n",
              "14            2       True         31  \n",
              "15            2       True         30  \n",
              "16            2       True         29  \n",
              "17            1       True          5  \n",
              "18            2       True         37  \n",
              "19            2       True         38  \n",
              "20            2       True         39  \n",
              "21            2       True         36  \n",
              "22            2       True         35  \n",
              "23            2       True         41  \n",
              "24            2       True         32  \n",
              "25            1       True         25  \n",
              "26            2       True         40  \n",
              "27            1       True         14  \n",
              "28            2       True         33  \n",
              "29            1       True          4  \n",
              "30            2       True         34  \n",
              "31            2       True         27  \n",
              "32            1       True          3  \n",
              "33            1       True         10  \n",
              "34            1       True         26  \n",
              "35            1       True         13  \n",
              "36            1       True         15  \n",
              "37            1       True         22  \n",
              "38            1       True         18  \n",
              "39            1       True         17  \n",
              "40            1       True          8  \n",
              "41            1       True          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d649f8b6-a544-40a5-92e9-fd56f67b7e11\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsDist_BAG_L1</td>\n",
              "      <td>-5.614085e-07</td>\n",
              "      <td>-6.577513</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.014902</td>\n",
              "      <td>0.013638</td>\n",
              "      <td>0.005910</td>\n",
              "      <td>0.014902</td>\n",
              "      <td>0.013638</td>\n",
              "      <td>0.005910</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost_r33_BAG_L1</td>\n",
              "      <td>-5.813374e-01</td>\n",
              "      <td>-3.849863</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.995560</td>\n",
              "      <td>0.261932</td>\n",
              "      <td>44.530389</td>\n",
              "      <td>0.995560</td>\n",
              "      <td>0.261932</td>\n",
              "      <td>44.530389</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost_r9_BAG_L1</td>\n",
              "      <td>-6.673254e-01</td>\n",
              "      <td>-3.565220</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.687863</td>\n",
              "      <td>0.044414</td>\n",
              "      <td>233.428024</td>\n",
              "      <td>0.687863</td>\n",
              "      <td>0.044414</td>\n",
              "      <td>233.428024</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost_r13_BAG_L1</td>\n",
              "      <td>-7.363171e-01</td>\n",
              "      <td>-3.385719</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.114889</td>\n",
              "      <td>0.024206</td>\n",
              "      <td>172.259996</td>\n",
              "      <td>0.114889</td>\n",
              "      <td>0.024206</td>\n",
              "      <td>172.259996</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>-7.762401e-01</td>\n",
              "      <td>-3.706454</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.541543</td>\n",
              "      <td>0.096619</td>\n",
              "      <td>23.378653</td>\n",
              "      <td>0.541543</td>\n",
              "      <td>0.096619</td>\n",
              "      <td>23.378653</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBMLarge_BAG_L1</td>\n",
              "      <td>-8.534829e-01</td>\n",
              "      <td>-3.711882</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.308167</td>\n",
              "      <td>0.060869</td>\n",
              "      <td>40.470383</td>\n",
              "      <td>1.308167</td>\n",
              "      <td>0.060869</td>\n",
              "      <td>40.470383</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>-8.743485e-01</td>\n",
              "      <td>-3.285920</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.350428</td>\n",
              "      <td>0.029414</td>\n",
              "      <td>266.716108</td>\n",
              "      <td>0.350428</td>\n",
              "      <td>0.029414</td>\n",
              "      <td>266.716108</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CatBoost_r177_BAG_L1</td>\n",
              "      <td>-9.242222e-01</td>\n",
              "      <td>-3.313882</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.217206</td>\n",
              "      <td>0.014112</td>\n",
              "      <td>58.107791</td>\n",
              "      <td>0.217206</td>\n",
              "      <td>0.014112</td>\n",
              "      <td>58.107791</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CatBoost_r137_BAG_L1</td>\n",
              "      <td>-1.069514e+00</td>\n",
              "      <td>-3.237796</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.096952</td>\n",
              "      <td>0.015640</td>\n",
              "      <td>121.723618</td>\n",
              "      <td>0.096952</td>\n",
              "      <td>0.015640</td>\n",
              "      <td>121.723618</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTrees_r42_BAG_L1</td>\n",
              "      <td>-1.220821e+00</td>\n",
              "      <td>-3.316153</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.106155</td>\n",
              "      <td>0.195372</td>\n",
              "      <td>0.963074</td>\n",
              "      <td>0.106155</td>\n",
              "      <td>0.195372</td>\n",
              "      <td>0.963074</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesMSE_BAG_L1</td>\n",
              "      <td>-1.248723e+00</td>\n",
              "      <td>-3.380886</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.259670</td>\n",
              "      <td>0.325630</td>\n",
              "      <td>0.992206</td>\n",
              "      <td>0.259670</td>\n",
              "      <td>0.325630</td>\n",
              "      <td>0.992206</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>-1.283963e+00</td>\n",
              "      <td>-2.599906</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.556818</td>\n",
              "      <td>1.622863</td>\n",
              "      <td>536.621618</td>\n",
              "      <td>0.002779</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.025008</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>-1.314485e+00</td>\n",
              "      <td>-2.938185</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.948161</td>\n",
              "      <td>1.307280</td>\n",
              "      <td>405.139572</td>\n",
              "      <td>1.051580</td>\n",
              "      <td>0.167506</td>\n",
              "      <td>40.940881</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RandomForest_r195_BAG_L1</td>\n",
              "      <td>-1.334612e+00</td>\n",
              "      <td>-3.611478</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>0.213756</td>\n",
              "      <td>1.157424</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>0.213756</td>\n",
              "      <td>1.157424</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>-1.348990e+00</td>\n",
              "      <td>-3.002192</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.969364</td>\n",
              "      <td>1.180667</td>\n",
              "      <td>430.461813</td>\n",
              "      <td>0.072783</td>\n",
              "      <td>0.040894</td>\n",
              "      <td>66.263122</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RandomForestMSE_BAG_L2</td>\n",
              "      <td>-1.350677e+00</td>\n",
              "      <td>-2.830589</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.013429</td>\n",
              "      <td>1.346871</td>\n",
              "      <td>366.972642</td>\n",
              "      <td>0.116849</td>\n",
              "      <td>0.207097</td>\n",
              "      <td>2.773951</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>-1.375651e+00</td>\n",
              "      <td>-2.741190</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.178673</td>\n",
              "      <td>1.225824</td>\n",
              "      <td>400.233994</td>\n",
              "      <td>0.282093</td>\n",
              "      <td>0.086050</td>\n",
              "      <td>36.035303</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RandomForestMSE_BAG_L1</td>\n",
              "      <td>-1.383482e+00</td>\n",
              "      <td>-3.728369</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.175035</td>\n",
              "      <td>0.267042</td>\n",
              "      <td>1.392886</td>\n",
              "      <td>0.175035</td>\n",
              "      <td>0.267042</td>\n",
              "      <td>1.392886</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CatBoost_r177_BAG_L2</td>\n",
              "      <td>-1.391755e+00</td>\n",
              "      <td>-2.956868</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.934484</td>\n",
              "      <td>1.190170</td>\n",
              "      <td>415.381309</td>\n",
              "      <td>0.037904</td>\n",
              "      <td>0.050396</td>\n",
              "      <td>51.182618</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L2</td>\n",
              "      <td>-1.392641e+00</td>\n",
              "      <td>-2.937632</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.047570</td>\n",
              "      <td>1.309542</td>\n",
              "      <td>449.521833</td>\n",
              "      <td>0.150990</td>\n",
              "      <td>0.169769</td>\n",
              "      <td>85.323143</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>LightGBM_r131_BAG_L2</td>\n",
              "      <td>-1.395600e+00</td>\n",
              "      <td>-2.826952</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.476198</td>\n",
              "      <td>1.213398</td>\n",
              "      <td>405.082612</td>\n",
              "      <td>0.579618</td>\n",
              "      <td>0.073625</td>\n",
              "      <td>40.883921</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>LightGBMLarge_BAG_L2</td>\n",
              "      <td>-1.402709e+00</td>\n",
              "      <td>-2.897142</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>9.732880</td>\n",
              "      <td>2.248622</td>\n",
              "      <td>472.040378</td>\n",
              "      <td>7.836300</td>\n",
              "      <td>1.108848</td>\n",
              "      <td>107.841687</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NeuralNetTorch_BAG_L2</td>\n",
              "      <td>-1.427870e+00</td>\n",
              "      <td>-2.822412</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.081068</td>\n",
              "      <td>1.352595</td>\n",
              "      <td>441.384588</td>\n",
              "      <td>0.184487</td>\n",
              "      <td>0.212821</td>\n",
              "      <td>77.185897</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>CatBoost_r9_BAG_L2</td>\n",
              "      <td>-1.431085e+00</td>\n",
              "      <td>-3.086243</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>1.989565</td>\n",
              "      <td>1.206998</td>\n",
              "      <td>467.499227</td>\n",
              "      <td>0.092985</td>\n",
              "      <td>0.067224</td>\n",
              "      <td>103.300536</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ExtraTreesMSE_BAG_L2</td>\n",
              "      <td>-1.440744e+00</td>\n",
              "      <td>-2.901206</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.017591</td>\n",
              "      <td>1.330935</td>\n",
              "      <td>365.652709</td>\n",
              "      <td>0.121010</td>\n",
              "      <td>0.191162</td>\n",
              "      <td>1.454018</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>LightGBM_r188_BAG_L1</td>\n",
              "      <td>-1.447488e+00</td>\n",
              "      <td>-3.363394</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.343110</td>\n",
              "      <td>0.157811</td>\n",
              "      <td>33.473389</td>\n",
              "      <td>0.343110</td>\n",
              "      <td>0.157811</td>\n",
              "      <td>33.473389</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NeuralNetFastAI_r191_BAG_L2</td>\n",
              "      <td>-1.470572e+00</td>\n",
              "      <td>-2.923406</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.087459</td>\n",
              "      <td>1.323292</td>\n",
              "      <td>423.375410</td>\n",
              "      <td>0.190879</td>\n",
              "      <td>0.183518</td>\n",
              "      <td>59.176719</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>LightGBM_r131_BAG_L1</td>\n",
              "      <td>-1.518600e+00</td>\n",
              "      <td>-3.600938</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.284922</td>\n",
              "      <td>0.087528</td>\n",
              "      <td>36.823365</td>\n",
              "      <td>2.284922</td>\n",
              "      <td>0.087528</td>\n",
              "      <td>36.823365</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2</td>\n",
              "      <td>-1.561181e+00</td>\n",
              "      <td>-2.975000</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.324497</td>\n",
              "      <td>1.365884</td>\n",
              "      <td>414.147531</td>\n",
              "      <td>0.427917</td>\n",
              "      <td>0.226110</td>\n",
              "      <td>49.948840</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>-1.585438e+00</td>\n",
              "      <td>-3.641612</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.268034</td>\n",
              "      <td>0.026541</td>\n",
              "      <td>32.076434</td>\n",
              "      <td>0.268034</td>\n",
              "      <td>0.026541</td>\n",
              "      <td>32.076434</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>-1.671690e+00</td>\n",
              "      <td>-3.020679</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>2.119350</td>\n",
              "      <td>1.211861</td>\n",
              "      <td>391.560862</td>\n",
              "      <td>0.222770</td>\n",
              "      <td>0.072087</td>\n",
              "      <td>27.362171</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>-1.797270e+00</td>\n",
              "      <td>-2.699152</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.788918</td>\n",
              "      <td>0.463249</td>\n",
              "      <td>305.258810</td>\n",
              "      <td>0.006048</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>0.038569</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>-1.929369e+00</td>\n",
              "      <td>-3.423726</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.511256</td>\n",
              "      <td>0.053407</td>\n",
              "      <td>34.548405</td>\n",
              "      <td>0.511256</td>\n",
              "      <td>0.053407</td>\n",
              "      <td>34.548405</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>NeuralNetTorch_BAG_L1</td>\n",
              "      <td>-2.109149e+00</td>\n",
              "      <td>-2.895835</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.481119</td>\n",
              "      <td>0.184984</td>\n",
              "      <td>128.625676</td>\n",
              "      <td>0.481119</td>\n",
              "      <td>0.184984</td>\n",
              "      <td>128.625676</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>NeuralNetFastAI_r145_BAG_L1</td>\n",
              "      <td>-2.286720e+00</td>\n",
              "      <td>-3.114751</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.204799</td>\n",
              "      <td>0.261952</td>\n",
              "      <td>54.870947</td>\n",
              "      <td>0.204799</td>\n",
              "      <td>0.261952</td>\n",
              "      <td>54.870947</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
              "      <td>-2.334841e+00</td>\n",
              "      <td>-2.928145</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.624557</td>\n",
              "      <td>0.160516</td>\n",
              "      <td>98.126449</td>\n",
              "      <td>0.624557</td>\n",
              "      <td>0.160516</td>\n",
              "      <td>98.126449</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
              "      <td>-2.712538e+00</td>\n",
              "      <td>-3.402761</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.651509</td>\n",
              "      <td>0.235071</td>\n",
              "      <td>60.698524</td>\n",
              "      <td>0.651509</td>\n",
              "      <td>0.235071</td>\n",
              "      <td>60.698524</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NeuralNetFastAI_r102_BAG_L1</td>\n",
              "      <td>-2.743220e+00</td>\n",
              "      <td>-3.294801</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.384085</td>\n",
              "      <td>0.221749</td>\n",
              "      <td>67.827288</td>\n",
              "      <td>0.384085</td>\n",
              "      <td>0.221749</td>\n",
              "      <td>67.827288</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>NeuralNetTorch_r22_BAG_L1</td>\n",
              "      <td>-2.763897e+00</td>\n",
              "      <td>-3.230574</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.566414</td>\n",
              "      <td>0.157992</td>\n",
              "      <td>100.923787</td>\n",
              "      <td>0.566414</td>\n",
              "      <td>0.157992</td>\n",
              "      <td>100.923787</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>LightGBM_r96_BAG_L1</td>\n",
              "      <td>-2.921761e+00</td>\n",
              "      <td>-3.907643</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>4.124207</td>\n",
              "      <td>0.242368</td>\n",
              "      <td>44.359431</td>\n",
              "      <td>4.124207</td>\n",
              "      <td>0.242368</td>\n",
              "      <td>44.359431</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>-2.941826e+00</td>\n",
              "      <td>-3.709525</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.335595</td>\n",
              "      <td>0.187045</td>\n",
              "      <td>48.391794</td>\n",
              "      <td>0.335595</td>\n",
              "      <td>0.187045</td>\n",
              "      <td>48.391794</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>KNeighborsUnif_BAG_L1</td>\n",
              "      <td>-5.428549e+00</td>\n",
              "      <td>-6.827997</td>\n",
              "      <td>root_mean_squared_error</td>\n",
              "      <td>0.015244</td>\n",
              "      <td>0.056002</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>0.015244</td>\n",
              "      <td>0.056002</td>\n",
              "      <td>0.008040</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d649f8b6-a544-40a5-92e9-fd56f67b7e11')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d649f8b6-a544-40a5-92e9-fd56f67b7e11 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d649f8b6-a544-40a5-92e9-fd56f67b7e11');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfaf1a92-8a62-4015-9052-41c5e8af3939\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfaf1a92-8a62-4015-9052-41c5e8af3939')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfaf1a92-8a62-4015-9052-41c5e8af3939 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 42,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"LightGBM_r188_BAG_L1\",\n          \"RandomForest_r195_BAG_L1\",\n          \"CatBoost_r137_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.887321186898289,\n        \"min\": -5.428548800165754,\n        \"max\": -5.614085050175813e-07,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          -1.4474876687986884,\n          -1.334611515012887,\n          -1.0695141523056944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8264419835714897,\n        \"min\": -6.827997397640703,\n        \"max\": -2.5999064398741223,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          -3.3633944792217023,\n          -3.6114780245451317,\n          -3.2377960760951967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"root_mean_squared_error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6719515704054173,\n        \"min\": 0.014902114868164062,\n        \"max\": 9.732880115509033,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.3431103229522705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6153001286581496,\n        \"min\": 0.013638019561767578,\n        \"max\": 2.248621702194214,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.15781140327453613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 184.38874712897487,\n        \"min\": 0.005910396575927734,\n        \"max\": 536.6216175556183,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          33.47338891029358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3423965942643674,\n        \"min\": 0.002778768539428711,\n        \"max\": 7.836299657821655,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.3431103229522705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17591622089155107,\n        \"min\": 0.0006725788116455078,\n        \"max\": 1.1088478565216064,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          0.15781140327453613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.40892448718246,\n        \"min\": 0.005910396575927734,\n        \"max\": 266.7161078453064,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          33.47338891029358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 42,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = predictor.predict(test_df.drop(columns=['target']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kT9qsLfbL790",
        "outputId": "f6a3c5ba-9717-4b13-d900-3dd2c84a0168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(test_df['target'],prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bm62cZ-MJN2",
        "outputId": "4b1141f0-78ac-43c2-880b-ecd7fab00abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.878150048029356"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0xqEp6uMPH0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}