{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshOne91/PLAYDATA-COLAB/blob/main/LLM%EC%9D%98_%EC%9D%91%EC%9A%A9(LLM_%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rag Langchain을 이용해서 한글문서를 기반으로 대화 맥락을 유지하면서 문서를 참조하는 챗봇\n",
        "```\n",
        "RAG : Retrieval Argumented Generation\n",
        "외부문서를 검색(Retrieval) 해서 LLM의 답변생성(Generation)을 강화하는 기술\n",
        "  문서검색 : 질문과 관련된 문서를 벡터 데이터베이스에서 검색\n",
        "  문서임베딩 : 텍스트를 벡터화(의미적 유사성)\n",
        "  답변생성 : 검색된 문서를 LLM전달해서 맥락에 맞는 답변 생성\n",
        "  장점 :\n",
        "  한글고려사항 : 다국어 임베딩등 다양한 임베딩 기법을 사용  \n",
        "LangChain : 오픈소스 프레임웍- LLM어플리케이션개발을 단순화\n",
        "  Prompt Templates : 동적 프롬프트 생성\n",
        "  Memory : 대화맥락 유지\n",
        "  Chains : 작업흐름관리\n",
        "  Retrival : 외부문서 검색\n",
        "  한글지원 잘됨, openai api와 호환\n",
        "  문서로드 : TextLoader-> Document객체 변환- 이후 문서를 작은단위로 분할(청크)\n",
        "```"
      ],
      "metadata": {
        "id": "fYXJGPhSzl62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '...'"
      ],
      "metadata": {
        "id": "HvwBhTyEx3fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -q"
      ],
      "metadata": {
        "id": "u4zCMgzM3AJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L7qW8E0M3Oav",
        "outputId": "cdaeb5f7-97d9-4472-e751-4ec53f94a4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.39)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.23 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "eUqiTh6B2gVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 로드\n",
        "loader = TextLoader('/content/korea_culture.txt')\n",
        "documents = loader.load()\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl3yuKD3285a",
        "outputId": "d752c5f2-49f5-4bf5-8129-7034cffa0191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/korea_culture.txt'}, page_content='대한민국은 동아시아에 위치한 나라로, 공식 명칭은 대한민국입니다.\\n한국의 수도는 서울이며, 서울은 약 970만 명의 인구를 가진 대도시입니다.\\n한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.\\n한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.\\n한국은 K-팝과 드라마로 전 세계적으로 문화적 영향력을 확대하고 있습니다.\\n한국의 주요 명절로는 설날과 추석이 있으며, 가족들이 모여 전통 음식을 나눕니다.\\n한국의 전통 의상인 한복은 색상과 디자인이 화려하며, 명절이나 결혼식에서 자주 입습니다.')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 분할\n",
        "text_splitter =  RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50,\n",
        "                                                separators=['\\n\\n', '\\n', '.', '!', '?', ',', ' '],\n",
        "                                                keep_separator=True)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DxXRTosP3eh_",
        "outputId": "5e439f8b-adf6-4553-d54f-f7a4426eae5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/korea_culture.txt'}, page_content='대한민국은 동아시아에 위치한 나라로, 공식 명칭은 대한민국입니다.\\n한국의 수도는 서울이며, 서울은 약 970만 명의 인구를 가진 대도시입니다.'),\n",
              " Document(metadata={'source': '/content/korea_culture.txt'}, page_content='한국의 수도는 서울이며, 서울은 약 970만 명의 인구를 가진 대도시입니다.\\n한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.'),\n",
              " Document(metadata={'source': '/content/korea_culture.txt'}, page_content='한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.\\n한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.'),\n",
              " Document(metadata={'source': '/content/korea_culture.txt'}, page_content='한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.\\n한국은 K-팝과 드라마로 전 세계적으로 문화적 영향력을 확대하고 있습니다.'),\n",
              " Document(metadata={'source': '/content/korea_culture.txt'}, page_content='한국은 K-팝과 드라마로 전 세계적으로 문화적 영향력을 확대하고 있습니다.\\n한국의 주요 명절로는 설날과 추석이 있으며, 가족들이 모여 전통 음식을 나눕니다.'),\n",
              " Document(metadata={'source': '/content/korea_culture.txt'}, page_content='한국의 주요 명절로는 설날과 추석이 있으며, 가족들이 모여 전통 음식을 나눕니다.\\n한국의 전통 의상인 한복은 색상과 디자인이 화려하며, 명절이나 결혼식에서 자주 입습니다.')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서의 내용 및 길이 확인\n",
        "with open('/content/korea_culture.txt', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "  print(f'문서길이 : {len(text)}')\n",
        "  temp = text.count('\\n')\n",
        "  print(f\"줄바꿈 수 : {temp}\")\n",
        "  print(f\"구분점 수 : {text.count('.')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ENqTEB4Ifs",
        "outputId": "a4f7fc45-58cc-4bde-bf8b-844980221d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서길이 : 294\n",
            "줄바꿈 수 : 6\n",
            "구분점 수 : 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_seperare_document(texts = 'korea_culture.txt',chunk_size=100,chunk_overlap=10):\n",
        "  # 문서로드\n",
        "  loader = TextLoader(texts)\n",
        "  documents = loader.load()\n",
        "  # 문서내용 및 길이 확인\n",
        "  with open(texts, encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    print(f'문서길이 : {len(text)}')\n",
        "    temp = text.count('\\n')\n",
        "    print(f\"줄바꿈 수 : {temp}\")\n",
        "    print(f\"구분점 수 : {text.count('.')}\")\n",
        "  # 문서 분할\n",
        "  # 분할된 청크를 반환\n",
        "  text_splitter =  RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap,\n",
        "                                                separators=['\\n\\n', '\\n', '.', '!', '?', ',', ' '],\n",
        "                                                keep_separator=True)\n",
        "  texts = text_splitter.split_documents(documents)\n",
        "  print(f'분할된 청크수 : {len(texts)}')\n",
        "  for i,chunk in enumerate(texts):\n",
        "    print(f'청크{i+1} : {chunk.page_content}')\n",
        "  return texts"
      ],
      "metadata": {
        "id": "Oljwgq_06AjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = load_and_seperare_document()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_MtMrMQ9IdH",
        "outputId": "52f0fabd-b888-45ad-fe95-699979499fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서길이 : 294\n",
            "줄바꿈 수 : 6\n",
            "구분점 수 : 7\n",
            "분할된 청크수 : 4\n",
            "청크1 : 대한민국은 동아시아에 위치한 나라로, 공식 명칭은 대한민국입니다.\n",
            "한국의 수도는 서울이며, 서울은 약 970만 명의 인구를 가진 대도시입니다.\n",
            "청크2 : 한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.\n",
            "한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.\n",
            "청크3 : 한국은 K-팝과 드라마로 전 세계적으로 문화적 영향력을 확대하고 있습니다.\n",
            "한국의 주요 명절로는 설날과 추석이 있으며, 가족들이 모여 전통 음식을 나눕니다.\n",
            "청크4 : 한국의 전통 의상인 한복은 색상과 디자인이 화려하며, 명절이나 결혼식에서 자주 입습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG 구현\n",
        "```\n",
        "  벡터데이터베이스 Chroma 가볍고 빠름 -> Langchain과잘 어울림\n",
        "  임베딩 : OepnAiEmbedding : 다국어 지원\n",
        "  검색 ; 질문도 벡터화해서 데이터베이스에 저장된 벡터와 유사도 검색\n",
        "\n",
        "  RetrivalQA체인:\n",
        "    질문->벡터데이터베이스 에서 문서 검색-> 검색된 문서를 LLM에 전달 ->답변\n",
        "```\n"
      ],
      "metadata": {
        "id": "bCgxYXbG90WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "SIswoBXADwXs",
        "outputId": "6acabb57-c00c-4b41-8ca9-3d089703f99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.4)\n",
            "Collecting fastapi==0.115.9 (from chromadb)\n",
            "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.30.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.33.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.33.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.54b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.33.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=a1ef305a1e65de5607476a4409a072656a83645b757f70a8b60595426b5fa316\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, uvicorn, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, importlib-metadata, humanfriendly, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.8 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 kubernetes-32.0.1 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.33.0 opentelemetry-exporter-otlp-proto-common-1.33.0 opentelemetry-exporter-otlp-proto-grpc-1.33.0 opentelemetry-instrumentation-0.54b0 opentelemetry-instrumentation-asgi-0.54b0 opentelemetry-instrumentation-fastapi-0.54b0 opentelemetry-proto-1.33.0 opentelemetry-sdk-1.33.0 opentelemetry-semantic-conventions-0.54b0 opentelemetry-util-http-0.54b0 overrides-7.7.0 posthog-4.0.1 pypika-0.48.9 starlette-0.45.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "cfd2a974cb6a4011a349d8c4f817e1a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '...'"
      ],
      "metadata": {
        "id": "uNYqr4vi9KZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM 초기화\n",
        "llm = OpenAI(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
        "# 벡터 데이터베이스 생성\n",
        "embeddings = OpenAIEmbeddings()\n",
        "texts = load_and_seperare_document()  # 청크분할\n",
        "vectorstore =  Chroma.from_documents(texts, embeddings, persist_directory='./db')\n",
        "# vectorstore.persist()  # 벡터 데이터 베이스 생성 완료  ince Chroma 0.4.x 이후에서는 자동으로 DB가 저장된다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BWwJwwgjB_X3",
        "outputId": "b699dc45-9ab4-443d-9369-fd118a8616b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서길이 : 294\n",
            "줄바꿈 수 : 6\n",
            "구분점 수 : 7\n",
            "분할된 청크수 : 4\n",
            "청크1 : 대한민국은 동아시아에 위치한 나라로, 공식 명칭은 대한민국입니다.\n",
            "한국의 수도는 서울이며, 서울은 약 970만 명의 인구를 가진 대도시입니다.\n",
            "청크2 : 한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.\n",
            "한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.\n",
            "청크3 : 한국은 K-팝과 드라마로 전 세계적으로 문화적 영향력을 확대하고 있습니다.\n",
            "한국의 주요 명절로는 설날과 추석이 있으며, 가족들이 모여 전통 음식을 나눕니다.\n",
            "청크4 : 한국의 전통 의상인 한복은 색상과 디자인이 화려하며, 명절이나 결혼식에서 자주 입습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RetrivalQA 체인 생성\n",
        "qa_chain =  RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = 'stuff', # 작은 문서는 분할하지않고 한번에 전달\n",
        "    retriever = vectorstore.as_retriever(search_kwargs = {'k':2}),  # 상위 2개 문서 검색\n",
        "    return_source_documents = True,\n",
        ")"
      ],
      "metadata": {
        "id": "tE1f3_MOCvFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 생성\n",
        "query = \"미국의 공식 언어는 무엇입니까?\"\n",
        "result = qa_chain({'query':query})\n",
        "# 결과 출력\n",
        "print(f'질문 : {query}')\n",
        "print(f'답변 : {result[\"result\"]}')\n",
        "print(f'참조 문서 : {[doc.page_content for doc in result[\"source_documents\"]]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L18rAILFIQ1",
        "outputId": "82ddd4c2-2d40-4c43-e856-b54d1747778b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 : 미국의 공식 언어는 무엇입니까?\n",
            "답변 :  미국의 공식 언어는 영어입니다.\n",
            "참조 문서 : ['한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.\\n한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.', '한국의 공식 언어는 한글로, 세종대왕이 1443년에 창제했습니다.\\n한국의 전통 음식으로는 김치, 불고기, 비빔밥, 떡볶이 등이 있습니다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단순 llm을 사용\n",
        "llm.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xz6BcSIzFu3V",
        "outputId": "fafbc6fb-02b0-48fd-f68b-4f1a982b1583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n미국의 공식 언어는 없지만, 영어가 사실상의 공식 언어로 사용되고 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 문서선택(text, pdf ,doc 등 다양한 문서 검색 기능을 지원)\n",
        "2. 문서를 기반으로 벡터데이터 베이스 생성 - RAG\n",
        "3. RAG를 기반으로 랭체인 구축(RAG를 통해 검색을 해서 해당 데이터를 LLM 전달 랭체인)"
      ],
      "metadata": {
        "id": "PuS9BbImG93b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 회사규정\n",
        "'''\n",
        "우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\n",
        "근태관리 기준은 8출근 5퇴근을 기준으로 한다\n",
        "금요일은 전사가 오전 근무만 한다\n",
        "재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "xSuslCf_G2NV",
        "outputId": "d6983194-e8fc-40ed-fbce-436c1dab8d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\\n근태관리 기준은 8출근 5퇴근을 기준으로 한다\\n금요일은 전사가 오전 근무만 한다\\n재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"우리회사의 재택근무는 어떻게 되나요?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "OAb-df0jH-h-",
        "outputId": "81977c46-7218-40bb-e940-d304d881d78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n저희 회사에서는 재택근무를 위한 시스템과 규정을 마련하고 있습니다. 재택근무는 업무의 특성상 가능한 경우에만 허용하고 있으며, 상사의 승인을 받아야 합니다.\\n\\n또한 재택근무를 할 때에도 근무시간, 출퇴근 기록 등 업무 관련 모든 사항은 업무시간 외에도 자율적으로 관리해야 합니다. 이를 위해 저희 회사에서는 재택근무 규정을 제공하고, 업무시간 외에도 업무 관련 사항을 관리할 수 있는 시스템을 제공하고 있습니다.\\n\\n또한 재택근무를 할 때에도 업무의 목적과 내용'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 회사규정\n",
        "company_rules = '''\n",
        "우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\n",
        "근태관리 기준은 8출근 5퇴근을 기준으로 한다\n",
        "금요일은 전사가 오전 근무만 한다\n",
        "재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\n",
        "'''\n",
        "with open('company_rules.txt', 'w') as f:\n",
        "  f.write(company_rules)\n",
        "\n",
        "# LLM 초기화\n",
        "llm = OpenAI(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
        "# 벡터 데이터베이스 생성\n",
        "embeddings = OpenAIEmbeddings()\n",
        "texts = load_and_seperare_document('company_rules.txt',chunk_size=50)  # 청크분할\n",
        "vectorstore =  Chroma.from_documents(texts, embeddings, persist_directory='./db3')\n",
        "# RetrivalQA 체인 생성\n",
        "qa_chain =  RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    # chain_type = 'stuff', # 작은 문서는 분할하지않고 한번에 전달\n",
        "    retriever = vectorstore.as_retriever(search_kwargs = {'k':5}),  # 상위 2개 문서 검색\n",
        "    return_source_documents = True,\n",
        ")\n",
        "# 질문 생성\n",
        "query = \"우리회사의 재택근무는 어떻게 되나요?\"\n",
        "result = qa_chain({'query':query})\n",
        "# 결과 출력\n",
        "print(f'질문 : {query}')\n",
        "print(f'답변 : {result[\"result\"]}')\n",
        "print(f'참조 문서 : {[doc.page_content for doc in result[\"source_documents\"]]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQU0v8zVNQNk",
        "outputId": "92802880-a0af-4d10-f02c-bce2f8a87f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서길이 : 122\n",
            "줄바꿈 수 : 5\n",
            "구분점 수 : 1\n",
            "분할된 청크수 : 3\n",
            "청크1 : 우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\n",
            "청크2 : 근태관리 기준은 8출근 5퇴근을 기준으로 한다\n",
            "금요일은 전사가 오전 근무만 한다\n",
            "청크3 : 재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\n",
            "질문 : 우리회사의 재택근무는 어떻게 되나요?\n",
            "답변 : \n",
            "\n",
            "정답: 재택근무는 원하는 경우 승인 없이 자유롭게 실시할 수 있습니다.\n",
            "참조 문서 : ['우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.', '우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.', '재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다', '재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다', '근태관리 기준은 8출근 5퇴근을 기준으로 한다\\n금요일은 전사가 오전 근무만 한다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8HCRJ64OiNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 청크사이즈, 참조문서의 개수 --> 파이퍼 파라메터\n",
        "!pip install -U langchain-community -q\n",
        "!pip install chromadb -q\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b97OrQQwKdXk",
        "outputId": "168b5f17-9bdd-48e6-ef73-6c9e70bba5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.59-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.76.2)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.3.39)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.11.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.59-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed langchain-core-0.3.59 langchain_openai-0.3.16 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "import os\n",
        "import shutil\n",
        "os.environ['OPENAI_API_KEY'] = '...'"
      ],
      "metadata": {
        "id": "A04v8FLDPap8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_seperare_document(texts = 'korea_culture.txt',chunk_size=100,chunk_overlap=10):\n",
        "  # 문서로드\n",
        "  loader = TextLoader(texts)\n",
        "  documents = loader.load()\n",
        "  # 문서내용 및 길이 확인\n",
        "  with open(texts, encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    print(f'문서길이 : {len(text)}')\n",
        "    temp = text.count('\\n')\n",
        "    print(f\"줄바꿈 수 : {temp}\")\n",
        "    print(f\"구분점 수 : {text.count('.')}\")\n",
        "  # 문서 분할\n",
        "  # 분할된 청크를 반환\n",
        "  text_splitter =  RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap,\n",
        "                                                separators=['\\n\\n', '\\n', '.', '!', '?', ',', ' '],\n",
        "                                                keep_separator=True)\n",
        "  texts = text_splitter.split_documents(documents)\n",
        "  print(f'분할된 청크수 : {len(texts)}')\n",
        "  for i,chunk in enumerate(texts):\n",
        "    print(f'청크{i+1} : {chunk.page_content}')\n",
        "  return texts"
      ],
      "metadata": {
        "id": "SizBywQJPnOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('./db001'):\n",
        "  shutil.rmtree('./db001')"
      ],
      "metadata": {
        "id": "QwQhi6hbSkX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 회사규정\n",
        "company_rules = '''\n",
        "우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\n",
        "근태관리 기준은 8출근 5퇴근을 기준으로 한다\n",
        "금요일은 전사가 오전 근무만 한다\n",
        "우리회사의 재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\n",
        "'''\n",
        "with open('company_rules.txt', 'w') as f:\n",
        "  f.write(company_rules)\n",
        "\n",
        "# LLM 초기화\n",
        "llm = OpenAI(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
        "# 벡터 데이터베이스 생성\n",
        "embeddings = OpenAIEmbeddings()\n",
        "texts = load_and_seperare_document('company_rules.txt',chunk_size=50,chunk_overlap=5)  # 청크분할\n",
        "# 기존 벡터데이터베이스를 삭제하고 다시 저장\n",
        "vectorstore =  Chroma.from_documents(texts, embeddings, persist_directory='./db2')\n",
        "# RetrivalQA 체인 생성\n",
        "qa_chain =  RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    # chain_type = 'stuff', # 작은 문서는 분할하지않고 한번에 전달\n",
        "    retriever = vectorstore.as_retriever(search_kwargs = {'k':3}),  # 상위 2개 문서 검색\n",
        "    return_source_documents = True,\n",
        ")\n",
        "# 질문 생성\n",
        "query = \"근태기준?\"\n",
        "result = qa_chain.invoke({'query':query})\n",
        "# 결과 출력\n",
        "print(f'\\n\\n질문 : {query}')\n",
        "print(f'답변 : {result[\"result\"]}')\n",
        "print(f'참조 문서 : {[doc.page_content for doc in result[\"source_documents\"]]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "deT9DwCEPvLN",
        "outputId": "96a64fd9-40b4-473a-a33c-f361fe80993d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서길이 : 128\n",
            "줄바꿈 수 : 5\n",
            "구분점 수 : 1\n",
            "분할된 청크수 : 3\n",
            "청크1 : 우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\n",
            "청크2 : 근태관리 기준은 8출근 5퇴근을 기준으로 한다\n",
            "금요일은 전사가 오전 근무만 한다\n",
            "청크3 : 우리회사의 재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\n",
            "\n",
            "\n",
            "질문 : 근태기준?\n",
            "답변 :  근태관리 기준은 8출근 5퇴근을 기준으로 한다.\n",
            "참조 문서 : ['근태관리 기준은 8출근 5퇴근을 기준으로 한다\\n금요일은 전사가 오전 근무만 한다', '근태관리 기준은 8출근 5퇴근을 기준으로 한다\\n금요일은 전사가 오전 근무만 한다', '근태관리 기준은 8출근 5퇴근을 기준으로 한다\\n금요일은 전사가 오전 근무만 한다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain 으로 다양한 문서 포멧 불러오기"
      ],
      "metadata": {
        "id": "qANlJBALRpEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i387lKAgU8uS",
        "outputId": "1d1aaeca-802f-416e-a705-a25e6f16a483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pdf 파일\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "loader = PyMuPDFLoader(\"/content/company_rules.pdf\")\n",
        "pages = loader.load()  # 페이지 단위로 문서를 분리\n",
        "pages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2eghRbLP40T",
        "outputId": "857bd592-a793-4e29-b0f7-3757b91cd215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Microsoft® Word Microsoft 365용', 'creator': 'Microsoft® Word Microsoft 365용', 'creationdate': '2025-05-12T11:32:39+09:00', 'source': '/content/company_rules.pdf', 'file_path': '/content/company_rules.pdf', 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': '이규영', 'subject': '', 'keywords': '', 'moddate': '2025-05-12T11:32:39+09:00', 'trapped': '', 'modDate': \"D:20250512113239+09'00'\", 'creationDate': \"D:20250512113239+09'00'\", 'page': 0}, page_content='우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다. \\n근태관리 기준은 8출근 5퇴근을 기준으로 한다 \\n금요일은 전사가 오전 근무만 한다 \\n우리회사의 재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다 \\n구분 \\n종류 \\n타입 \\n가격 \\n사무용 \\n개인용품 \\nA타입 \\n5000')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "szGHaEfgWQZT",
        "outputId": "b2e3e653-b43b-418e-857b-7b84c9268fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.4)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.0.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.34.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2025.4.26)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (2.11.4)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Downloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.34.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=78cbad7dc90109daef1b94fcabce829b90d6da3d23cb4d9837770d334e4985a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, olefile, langdetect, eval-type-backport, emoji, aiofiles, python-oxmsg, unstructured-client, unstructured\n",
            "Successfully installed aiofiles-24.1.0 emoji-2.14.1 eval-type-backport-0.2.2 filetype-1.2.0 langdetect-1.0.9 olefile-0.47 pypdf-5.5.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 unstructured-0.17.2 unstructured-client-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b6nbTPKSWvsC",
        "outputId": "8d2caacc-7338-4bf0-9cea-377df54bf980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 워드문서 로드\n",
        "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
        "loader = UnstructuredWordDocumentLoader(\"/content/company_rules.docx\")\n",
        "pages = loader.load()  # 페이지 단위로 문서를 분리\n",
        "pages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqUaqfSvU6XV",
        "outputId": "0f136d06-60e6-48cf-a52f-b1776c119a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/company_rules.docx'}, page_content='우리 회사의 정규직 전환은 수습기간 4개월후 평가를 거쳐 결정된다.\\n\\n근태관리 기준은 8출근 5퇴근을 기준으로 한다\\n\\n금요일은 전사가 오전 근무만 한다\\n\\n우리회사의 재택근무는 본인이 원하면 누구의 승인도 받지 않고 자유롭게 실시한다\\n\\n구분 종류 타입 가격 사무용 개인용품 A타입 5000')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'name' : ['Alice', 'Bob', 'Charlie'],\n",
        "    'age' : [25, 30, 35],\n",
        "    'city' : ['New York', 'San Francisco', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('example.csv', index=False)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "b9Y5dcgPXmWv",
        "outputId": "0cf4d5c7-fd2e-4f59-8fbd-76ab3d7d0d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      name  age           city\n",
              "0    Alice   25       New York\n",
              "1      Bob   30  San Francisco\n",
              "2  Charlie   35    Los Angeles"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f79a9fbc-60d4-479b-a4f8-7511f11d9b9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>age</th>\n",
              "      <th>city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alice</td>\n",
              "      <td>25</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bob</td>\n",
              "      <td>30</td>\n",
              "      <td>San Francisco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Charlie</td>\n",
              "      <td>35</td>\n",
              "      <td>Los Angeles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f79a9fbc-60d4-479b-a4f8-7511f11d9b9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f79a9fbc-60d4-479b-a4f8-7511f11d9b9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f79a9fbc-60d4-479b-a4f8-7511f11d9b9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2f657fe0-76ab-4a34-b429-85d25cea7ce0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f657fe0-76ab-4a34-b429-85d25cea7ce0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2f657fe0-76ab-4a34-b429-85d25cea7ce0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a4abe133-7e7d-4458-8674-f9164ff1cbe8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a4abe133-7e7d-4458-8674-f9164ff1cbe8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Alice\",\n          \"Bob\",\n          \"Charlie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 25,\n        \"max\": 35,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          25,\n          30,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"San Francisco\",\n          \"Los Angeles\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# csv 로드\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "loader = CSVLoader(\"example.csv\")\n",
        "pages = loader.load()\n",
        "pages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XeorRN-WOgy",
        "outputId": "650dbce6-555d-462f-db3d-35dc18303170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'example.csv', 'row': 0}, page_content='name: Alice\\nage: 25\\ncity: New York'),\n",
              " Document(metadata={'source': 'example.csv', 'row': 1}, page_content='name: Bob\\nage: 30\\ncity: San Francisco'),\n",
              " Document(metadata={'source': 'example.csv', 'row': 2}, page_content='name: Charlie\\nage: 35\\ncity: Los Angeles')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹페이지 로드\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\"https://github.com/sknetworks20250226/AI\")\n",
        "pages = loader.load()\n",
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AvvX-T9mXyEj",
        "outputId": "c9c988e4-cfdb-4fa3-d69f-c2d2115c182d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://github.com/sknetworks20250226/AI', 'title': 'GitHub - sknetworks20250226/AI', 'description': 'Contribute to sknetworks20250226/AI development by creating an account on GitHub.', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub - sknetworks20250226/AI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\nGitHub Advanced Security\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\nCodespaces\\n        Instant dev environments\\n      \\n\\n\\n\\n\\n\\n\\n\\nIssues\\n        Plan and track work\\n      \\n\\n\\n\\n\\n\\n\\n\\nCode Review\\n        Manage code changes\\n      \\n\\n\\n\\n\\n\\n\\n\\nDiscussions\\n        Collaborate outside of code\\n      \\n\\n\\n\\n\\n\\n\\n\\nCode Search\\n        Find more, search less\\n      \\n\\n\\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Why GitHub\\n\\n    \\n\\n\\n\\n      All features\\n\\n    \\n\\n\\n\\n      Documentation\\n\\n    \\n\\n\\n\\n\\n\\n      GitHub Skills\\n\\n    \\n\\n\\n\\n\\n\\n      Blog\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Solutions\\n        \\n\\n\\n\\n\\n\\n\\nBy company size\\n\\n\\n\\n      Enterprises\\n\\n    \\n\\n\\n\\n      Small and medium teams\\n\\n    \\n\\n\\n\\n      Startups\\n\\n    \\n\\n\\n\\n      Nonprofits\\n\\n    \\n\\n\\n\\n\\nBy use case\\n\\n\\n\\n      DevSecOps\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      CI/CD\\n\\n    \\n\\n\\n\\n      View all use cases\\n\\n    \\n\\n\\n\\n\\n\\n\\nBy industry\\n\\n\\n\\n      Healthcare\\n\\n    \\n\\n\\n\\n      Financial services\\n\\n    \\n\\n\\n\\n      Manufacturing\\n\\n    \\n\\n\\n\\n      Government\\n\\n    \\n\\n\\n\\n      View all industries\\n\\n    \\n\\n\\n\\n\\n\\n\\n              View all solutions\\n              \\n\\n\\n \\n\\n\\n\\n\\n        Resources\\n        \\n\\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n      AI\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      Security\\n\\n    \\n\\n\\n\\n      Software Development\\n\\n    \\n\\n\\n\\n      View all\\n\\n    \\n\\n\\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Learning Pathways\\n\\n    \\n\\n\\n\\n\\n\\n      Events & Webinars\\n\\n    \\n\\n\\n\\n\\n\\n      Ebooks & Whitepapers\\n\\n    \\n\\n\\n\\n      Customer Stories\\n\\n    \\n\\n\\n\\n      Partners\\n\\n    \\n\\n\\n\\n\\n\\n      Executive Insights\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n        Open Source\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Sponsors\\n        Fund open source developers\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\nThe ReadME Project\\n        GitHub community articles\\n      \\n\\n\\n\\n\\nRepositories\\n\\n\\n\\n      Topics\\n\\n    \\n\\n\\n\\n      Trending\\n\\n    \\n\\n\\n\\n      Collections\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n        Enterprise\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEnterprise platform\\n        AI-powered developer platform\\n      \\n\\n\\n\\n\\nAvailable add-ons\\n\\n\\n\\n\\n\\n\\n\\nGitHub Advanced Security\\n        Enterprise-grade security features\\n      \\n\\n\\n\\n\\n\\n\\n\\nCopilot for business\\n        Enterprise-grade AI features\\n      \\n\\n\\n\\n\\n\\n\\n\\nPremium Support\\n        Enterprise-grade 24/7 support\\n      \\n\\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch or jump to...\\n\\n\\n\\n\\n\\n\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\n \\n\\n\\n\\n\\n        Search\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClear\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nSearch syntax tips \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Provide feedback\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nWe read every piece of feedback, and take your input very seriously.\\n\\n\\nInclude my email address so I can be contacted\\n\\n\\n     Cancel\\n\\n    Submit feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Saved searches\\n      \\nUse saved searches to filter your results more quickly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\nQuery\\n\\n\\n\\n            To see all available qualifiers, see our documentation.\\n          \\n \\n\\n\\n\\n\\n\\n     Cancel\\n\\n    Create saved search\\n\\n\\n\\n\\n\\n\\n\\n\\n                Sign in\\n              \\n\\n\\n                Sign up\\n              \\n\\n\\n \\n\\n\\nAppearance settings\\n\\n\\n\\nReseting focus\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\n \\n\\n\\nDismiss alert\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        sknetworks20250226\\n \\n/\\n\\nAI\\n\\nPublic\\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n \\n\\nFork\\n    0\\n\\n\\n\\n\\n \\n\\n\\n          Star\\n 0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0\\n          stars\\n \\n\\n\\n\\n0\\n          forks\\n \\n\\n\\n\\nBranches\\n \\n\\n\\n\\nTags\\n \\n\\n\\n\\nActivity\\n \\n\\n\\n\\n \\n\\n\\n          Star\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\n\\n\\n\\nIssues\\n0\\n\\n\\n\\n\\n\\n\\nPull requests\\n0\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\n\\n\\n\\n\\n\\nProjects\\n0\\n\\n\\n\\n\\n\\n\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\nInsights\\n\\n\\n\\n \\n\\n \\n\\n\\nAdditional navigation options\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Pull requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Projects\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Insights\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nsknetworks20250226/AI\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   \\xa0mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit\\xa0History11 Commitsdatadata\\xa0\\xa0README.mdREADME.md\\xa0\\xa0View all filesRepository files navigationREADMEPFAS 대체 소재 개발을 위한 AI 활용 물성/합성 분석 기술 개발 제안서\\n1. 사업 개요\\n1.1 사업 배경\\n\\n글로벌 환경 규제 강화에 따른 PFAS 대체 소재 개발 필요성 증가\\n기존 양자 전산모사의 기술적 한계 극복 필요\\nAI 기반 신소재 개발 기술의 글로벌 경쟁력 확보 필요\\n\\n1.2 사업 목적\\n\\nPFAS 대체 소재 개발을 위한 AI 기반 가상 합성 환경 구축\\n분자 구조 설계 및 합성 모사 모듈 개발\\n물성 예측 및 합성 최적화 AI 모델 개발 (목표 정확도: 95% 이상)\\n\\n2. 기술 개발 내용\\n2.1 핵심 기술 개발\\n2.1.1 AI 기반 가상 합성 환경 구축\\n1. 분자 구조 설계 시스템\\nclass MolecularDesignSystem:\\n    def __init__(self):\\n        self.gnn = GraphNeuralNetwork()\\n        self.transformer = MolecularTransformer()\\n        self.optimizer = GeneticAlgorithm()\\n        self.validator = MolecularValidator()\\n        \\n    def design_molecule(self, target_properties):\\n        # 1. 초기 구조 생성\\n        initial_structures = self._generate_initial_structures(target_properties)\\n        \\n        # 2. 구조 최적화\\n        optimized_structures = self._optimize_structures(initial_structures)\\n        \\n        # 3. 물성 예측\\n        predicted_properties = self._predict_properties(optimized_structures)\\n        \\n        # 4. 구조 검증\\n        validated_structures = self._validate_structures(optimized_structures)\\n        \\n        return validated_structures\\n\\n    def _generate_initial_structures(self, properties):\\n        # GNN 기반 구조 생성\\n        structures = self.gnn.generate(properties)\\n        return structures\\n\\n    def _optimize_structures(self, structures):\\n        # 유전 알고리즘 기반 최적화\\n        optimized = self.optimizer.optimize(structures)\\n        return optimized\\n수학적 공식화:\\n\\n\\n분자 구조 표현\\n\\n분자 그래프 ( G = (V, E) )\\n( V ): 원자 노드 집합\\n( E ): 결합 엣지 집합\\n노드 특성: ( h_v \\\\in \\\\mathbb{R}^d )\\n엣지 특성: ( e_{uv} \\\\in \\\\mathbb{R}^k )\\n\\n\\n\\nGNN 기반 구조 생성\\n\\n메시지 전달 함수:\\n[\\nm_{v}^{(t)} = \\\\sum_{u \\\\in N(v)} M_t(h_v^{(t-1)}, h_u^{(t-1)}, e_{uv})\\n]\\n노드 업데이트:\\n[\\nh_v^{(t)} = U_t(h_v^{(t-1)}, m_v^{(t)})\\n]\\n최종 구조 예측:\\n[\\nP(G|p) = \\\\prod_{v \\\\in V} P(v|h_v^{(T)}) \\\\prod_{(u,v) \\\\in E} P(e_{uv}|h_u^{(T)}, h_v^{(T)})\\n]\\n\\n\\n\\n유전 알고리즘 최적화\\n\\n적합도 함수:\\n[\\nf(G) = \\\\sum_{i} w_i \\\\cdot |p_i - \\\\hat{p}_i|\\n]\\n선택 확률:\\n[\\nP(G_i) = \\\\frac{f(G_i)}{\\\\sum_j f(G_j)}\\n]\\n\\n\\n\\n2. 합성 모사 모듈\\nclass SynthesisSimulator:\\n    def __init__(self):\\n        self.reaction_predictor = ReactionPredictor()\\n        self.condition_simulator = ConditionSimulator()\\n        self.path_optimizer = PathOptimizer()\\n        \\n    def simulate_synthesis(self, target_molecule):\\n        # 1. 반응 예측\\n        reactions = self._predict_reactions(target_molecule)\\n        \\n        # 2. 조건 시뮬레이션\\n        conditions = self._simulate_conditions(reactions)\\n        \\n        # 3. 경로 최적화\\n        optimal_path = self._optimize_path(conditions)\\n        \\n        return optimal_path\\n\\n    def _predict_reactions(self, molecule):\\n        # 반응 예측\\n        reactions = self.reaction_predictor.predict(molecule)\\n        return reactions\\n\\n    def _simulate_conditions(self, reactions):\\n        # 조건 시뮬레이션\\n        conditions = self.condition_simulator.simulate(reactions)\\n        return conditions\\n수학적 공식화:\\n\\n\\n반응 예측 모델\\n\\n반응 확률:\\n[\\nP(r|m) = \\\\frac{\\\\exp(s(m,r))}{\\\\sum_{r'}\\\\exp(s(m,r'))}\\n]\\n점수 함수:\\n[\\ns(m,r) = \\\\text{MLP}([\\\\text{GNN}(m), \\\\text{Embedding}(r)])\\n]\\n\\n\\n\\n조건 시뮬레이션\\n\\n반응 속도:\\n[\\nr = k \\\\cdot \\\\prod_i [A_i]^{\\\\alpha_i}\\n]\\n온도 의존성:\\n[\\nk = A \\\\cdot e^{-\\\\frac{E_a}{RT}}\\n]\\n\\n\\n\\n경로 최적화\\n\\n목적 함수:\\n[\\n\\\\min_{\\\\pi} \\\\sum_{t} c(s_t, a_t) + \\\\lambda \\\\cdot \\\\text{risk}(s_t)\\n]\\n벨만 방정식:\\n[\\nV(s) = \\\\min_a {c(s,a) + \\\\gamma \\\\cdot \\\\mathbb{E}[V(s')]}\\n]\\n\\n\\n\\n3. 실험 데이터베이스 시스템\\nclass ExperimentalDatabase:\\n    def __init__(self):\\n        self.data_processor = DataProcessor()\\n        self.data_validator = DataValidator()\\n        self.data_analyzer = DataAnalyzer()\\n        \\n    def process_data(self, raw_data):\\n        # 1. 데이터 전처리\\n        processed_data = self._preprocess_data(raw_data)\\n        \\n        # 2. 데이터 검증\\n        validated_data = self._validate_data(processed_data)\\n        \\n        # 3. 데이터 분석\\n        analyzed_data = self._analyze_data(validated_data)\\n        \\n        return analyzed_data\\n\\n    def _preprocess_data(self, data):\\n        # 데이터 전처리\\n        processed = self.data_processor.process(data)\\n        return processed\\n수학적 공식화:\\n\\n\\n데이터 전처리\\n\\n정규화:\\n[\\nx' = \\\\frac{x - \\\\mu}{\\\\sigma}\\n]\\n이상치 제거:\\n[\\n\\\\text{outlier} = |x - \\\\mu| > 3\\\\sigma\\n]\\n\\n\\n\\n데이터 검증\\n\\n일관성 검사:\\n[\\n\\\\text{consistency} = \\\\frac{1}{n}\\\\sum_{i=1}^n \\\\mathbb{I}(x_i \\\\in \\\\text{valid_range})\\n]\\n상관관계 검증:\\n[\\n\\\\rho = \\\\frac{\\\\text{cov}(X,Y)}{\\\\sigma_X \\\\sigma_Y}\\n]\\n\\n\\n\\n2.1.2 물성 예측 시스템\\n1. 물성 예측 모델\\nclass PropertyPredictor:\\n    def __init__(self):\\n        self.insulation_predictor = InsulationPredictor()\\n        self.heat_resistance_predictor = HeatResistancePredictor()\\n        self.flame_retardant_predictor = FlameRetardantPredictor()\\n        \\n    def predict_properties(self, molecule):\\n        # 1. 절연성 예측\\n        insulation = self._predict_insulation(molecule)\\n        \\n        # 2. 내열성 예측\\n        heat_resistance = self._predict_heat_resistance(molecule)\\n        \\n        # 3. 불연성 예측\\n        flame_retardant = self._predict_flame_retardant(molecule)\\n        \\n        return {\\n            'insulation': insulation,\\n            'heat_resistance': heat_resistance,\\n            'flame_retardant': flame_retardant\\n        }\\n\\n    def _predict_insulation(self, molecule):\\n        # 절연성 예측\\n        return self.insulation_predictor.predict(molecule)\\n수학적 공식화:\\n\\n\\n다중 물성 예측\\n\\n공동 학습 목적 함수:\\n[\\n\\\\mathcal{L} = \\\\sum_{i=1}^k w_i \\\\cdot \\\\mathcal{L}_i + \\\\lambda \\\\cdot |\\\\theta|_2^2\\n]\\n각 물성 예측:\\n[\\n\\\\hat{y}_i = f_i(\\\\text{GNN}(G); \\\\theta_i)\\n]\\n\\n\\n\\n불확실성 정량화\\n\\n예측 분포:\\n[\\np(y|x) = \\\\mathcal{N}(\\\\mu(x), \\\\sigma^2(x))\\n]\\n불확실성:\\n[\\n\\\\text{uncertainty} = \\\\sqrt{\\\\mathbb{E}[\\\\sigma^2(x)] + \\\\text{Var}[\\\\mu(x)]}\\n]\\n\\n\\n\\n2. 분자 구조-물성 관계 분석 시스템\\nclass StructurePropertyAnalyzer:\\n    def __init__(self):\\n        self.correlation_analyzer = CorrelationAnalyzer()\\n        self.pattern_analyzer = PatternAnalyzer()\\n        self.relationship_model = RelationshipModel()\\n        \\n    def analyze_relationship(self, structures, properties):\\n        # 1. 상관관계 분석\\n        correlations = self._analyze_correlations(structures, properties)\\n        \\n        # 2. 패턴 분석\\n        patterns = self._analyze_patterns(structures, properties)\\n        \\n        # 3. 관계 모델링\\n        model = self._model_relationships(correlations, patterns)\\n        \\n        return model\\n\\n    def _analyze_correlations(self, structures, properties):\\n        # 상관관계 분석\\n        return self.correlation_analyzer.analyze(structures, properties)\\n수학적 공식화:\\n\\n\\n상관관계 분석\\n\\n부분 상관계수:\\n[\\n\\\\rho_{XY|Z} = \\\\frac{\\\\rho_{XY} - \\\\rho_{XZ}\\\\rho_{YZ}}{\\\\sqrt{(1-\\\\rho_{XZ}^2)(1-\\\\rho_{YZ}^2)}}\\n]\\n중요도 점수:\\n[\\nI(f) = \\\\sum_{S \\\\subseteq F \\\\setminus {f}} \\\\frac{|S|!(|F|-|S|-1)!}{|F|!} \\\\cdot \\\\Delta(f,S)\\n]\\n\\n\\n\\n패턴 인식\\n\\n그래프 커널:\\n[\\nK(G,G') = \\\\sum_{k=0}^\\\\infty \\\\lambda^k \\\\cdot \\\\langle \\\\phi_k(G), \\\\phi_k(G') \\\\rangle\\n]\\n패턴 매칭:\\n[\\n\\\\text{similarity} = \\\\frac{\\\\sum_{i} \\\\min(x_i, y_i)}{\\\\sum_{i} \\\\max(x_i, y_i)}\\n]\\n\\n\\n\\n2.1.3 합성 최적화 시스템\\n1. 합성 경로 예측 알고리즘\\nclass SynthesisPathPredictor:\\n    def __init__(self):\\n        self.reaction_predictor = ReactionPredictor()\\n        self.path_generator = PathGenerator()\\n        self.path_evaluator = PathEvaluator()\\n        \\n    def predict_path(self, target_molecule):\\n        # 1. 반응 예측\\n        reactions = self._predict_reactions(target_molecule)\\n        \\n        # 2. 경로 생성\\n        paths = self._generate_paths(reactions)\\n        \\n        # 3. 경로 평가\\n        optimal_path = self._evaluate_paths(paths)\\n        \\n        return optimal_path\\n\\n    def _predict_reactions(self, molecule):\\n        # 반응 예측\\n        return self.reaction_predictor.predict(molecule)\\n수학적 공식화:\\n\\n\\n경로 생성\\n\\n상태 전이 확률:\\n[\\nP(s_{t+1}|s_t,a_t) = \\\\text{softmax}(W \\\\cdot [s_t,a_t])\\n]\\n보상 함수:\\n[\\nR(s,a) = \\\\alpha \\\\cdot \\\\text{yield} + \\\\beta \\\\cdot \\\\text{cost} + \\\\gamma \\\\cdot \\\\text{safety}\\n]\\n\\n\\n\\n경로 평가\\n\\n최적 경로:\\n[\\n\\\\pi^* = \\\\arg\\\\max_\\\\pi \\\\mathbb{E}[\\\\sum_{t=0}^T \\\\gamma^t R(s_t,a_t)]\\n]\\n정책 기울기:\\n[\\n\\\\nabla_\\\\theta J(\\\\theta) = \\\\mathbb{E}[\\\\sum_{t=0}^T \\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_t|s_t) \\\\cdot Q^\\\\pi(s_t,a_t)]\\n]\\n\\n\\n\\n2. 반응 조건 최적화 모델\\nclass ReactionConditionOptimizer:\\n    def __init__(self):\\n        self.condition_predictor = ConditionPredictor()\\n        self.optimizer = ConditionOptimizer()\\n        self.validator = ConditionValidator()\\n        \\n    def optimize_conditions(self, reaction):\\n        # 1. 조건 예측\\n        conditions = self._predict_conditions(reaction)\\n        \\n        # 2. 조건 최적화\\n        optimized = self._optimize_conditions(conditions)\\n        \\n        # 3. 조건 검증\\n        validated = self._validate_conditions(optimized)\\n        \\n        return validated\\n\\n    def _predict_conditions(self, reaction):\\n        # 조건 예측\\n        return self.condition_predictor.predict(reaction)\\n수학적 공식화:\\n\\n\\n조건 최적화\\n\\n목적 함수:\\n[\\n\\\\min_{x} f(x) = \\\\text{yield}(x) + \\\\lambda \\\\cdot \\\\text{cost}(x)\\n]\\n제약 조건:\\n[\\ng_i(x) \\\\leq 0, \\\\quad i = 1,...,m\\n]\\n\\n\\n\\n베이지안 최적화\\n\\n획득 함수:\\n[\\n\\\\alpha(x) = \\\\mu(x) + \\\\kappa \\\\cdot \\\\sigma(x)\\n]\\n사후 분포:\\n[\\np(f|D) = \\\\mathcal{N}(\\\\mu(x), k(x,x'))\\n]\\n\\n\\n\\n3. 실시간 모니터링 시스템\\nclass RealTimeMonitor:\\n    def __init__(self):\\n        self.data_collector = DataCollector()\\n        self.analyzer = DataAnalyzer()\\n        self.alert_system = AlertSystem()\\n        \\n    def monitor(self, synthesis_process):\\n        # 1. 데이터 수집\\n        data = self._collect_data(synthesis_process)\\n        \\n        # 2. 데이터 분석\\n        analysis = self._analyze_data(data)\\n        \\n        # 3. 알림 처리\\n        alerts = self._process_alerts(analysis)\\n        \\n        return alerts\\n\\n    def _collect_data(self, process):\\n        # 데이터 수집\\n        return self.data_collector.collect(process)\\n수학적 공식화:\\n\\n\\n이상 감지\\n\\n마할라노비스 거리:\\n[\\nD(x) = \\\\sqrt{(x-\\\\mu)^T \\\\Sigma^{-1} (x-\\\\mu)}\\n]\\n이상치 점수:\\n[\\n\\\\text{score} = \\\\frac{|x - \\\\text{median}|}{\\\\text{MAD}}\\n]\\n\\n\\n\\n시계열 분석\\n\\n자기상관:\\n[\\n\\\\rho_k = \\\\frac{\\\\sum_{t=k+1}^T (x_t - \\\\bar{x})(x_{t-k} - \\\\bar{x})}{\\\\sum_{t=1}^T (x_t - \\\\bar{x})^2}\\n]\\n이동 평균:\\n[\\n\\\\text{MA}(t) = \\\\frac{1}{w} \\\\sum_{i=0}^{w-1} x_{t-i}\\n]\\n\\n\\n\\n2.2 시스템 아키텍처\\n2.2.1 전체 시스템 아키텍처\\n┌─────────────────────────────────────────────────────────────┐\\n│                     AI 기반 가상 합성 환경                     │\\n└─────────────────────────────────────────────────────────────┘\\n                            │\\n                            ▼\\n┌─────────────────────────────────────────────────────────────┐\\n│                     분자 구조 설계 시스템                      │\\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │\\n│  │ 구조 생성   │  │ 구조 최적화 │  │ 구조 검증          │  │\\n│  └─────────────┘  └─────────────┘  └─────────────────────┘  │\\n└─────────────────────────────────────────────────────────────┘\\n                            │\\n                            ▼\\n┌─────────────────────────────────────────────────────────────┐\\n│                     물성 예측 시스템                          │\\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │\\n│  │ 절연성 예측 │  │ 내열성 예측 │  │ 불연성 예측        │  │\\n│  └─────────────┘  └─────────────┘  └─────────────────────┘  │\\n└─────────────────────────────────────────────────────────────┘\\n                            │\\n                            ▼\\n┌─────────────────────────────────────────────────────────────┐\\n│                     합성 최적화 시스템                        │\\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │\\n│  │ 경로 예측   │  │ 조건 최적화 │  │ 실시간 모니터링    │  │\\n│  └─────────────┘  └─────────────┘  └─────────────────────┘  │\\n└─────────────────────────────────────────────────────────────┘\\n\\n2.2.2 데이터 흐름 아키텍처\\n┌─────────────────────────────────────────────────────────────┐\\n│                     실험 데이터베이스                          │\\n└─────────────────────────────────────────────────────────────┘\\n                            │\\n                            ▼\\n┌─────────────────────────────────────────────────────────────┐\\n│                     데이터 전처리 시스템                      │\\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │\\n│  │ 데이터 정제 │  │ 데이터 변환 │  │ 데이터 검증        │  │\\n│  └─────────────┘  └─────────────┘  └─────────────────────┘  │\\n└─────────────────────────────────────────────────────────────┘\\n                            │\\n                            ▼\\n┌─────────────────────────────────────────────────────────────┐\\n│                     AI 모델 학습 시스템                       │\\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │\\n│  │ 모델 학습   │  │ 모델 검증   │  │ 모델 최적화        │  │\\n│  └─────────────┘  └─────────────┘  └─────────────────────┘  │\\n└─────────────────────────────────────────────────────────────┘\\n\\n3. 기술 개발 로드맵\\n3.1 1차년도 (9개월)\\n\\n가상 합성 환경 구축\\n기본 AI 모델 개발\\n실험 데이터베이스 구축\\n\\n3.2 2차년도 (10개월)\\n\\n고성능 AI 모델 개발\\n합성 최적화 시스템 구현\\n성능 검증\\n\\n3.3 3차년도 (12개월)\\n\\n실 제조환경 실증\\n시스템 안정화\\n상용화 준비\\n\\n3.4 4차년도 (2개월)\\n\\n최종 시스템 검증\\n기술 이전\\n\\n4. 기대효과\\n4.1 기술적 효과\\n\\nAI 기반 합성 예측 정확도 95% 이상 달성\\n개발 시간 50% 단축\\n실험 비용 70% 절감\\n\\n4.2 산업적 효과\\n\\nPFAS 대체 소재 개발 가속화\\n국내 소재 산업 경쟁력 강화\\n글로벌 시장 진출 기반 마련\\n\\n4.3 경제적 효과\\n\\n2032년까지 2,579억 달러 규모의 이차전지 시장 진출\\n기술 수출 및 라이선싱 기회 창출\\n고용 창출 및 부가가치 증대\\n\\n5. 사업화 계획\\n5.1 시장 분석\\n\\n글로벌 이차전지 시장 규모: 2023년 1,173억 달러\\n예상 시장 규모: 2032년 2,579억 달러 (CAGR 9%)\\n주요 경쟁사: CATL, BYD, EnerSys\\n\\n5.2 사업화 전략\\n\\n기술 특허 출원 및 보호\\n글로벌 기업과의 전략적 제휴\\n단계적 시장 진출 계획\\n\\n5.3 수익 모델\\n\\n시스템 판매\\n기술 라이선싱\\n유지보수 및 기술 지원\\n\\n6. 투자 계획\\n6.1 투자 규모\\n\\n총 투자액: 30.31억원\\n정부 지원금: 10.31억원\\n자체 투자금: 20억원\\n\\n6.2 투자 계획\\n\\n연구개발비: 25억원\\n인건비: 3억원\\n운영비: 2.31억원\\n\\n7. 위험 요소 및 대응 방안\\n7.1 기술적 위험\\n\\n\\n위험: AI 모델의 예측 정확도\\n\\n대응: 다중 모델 앙상블 및 실험 데이터 검증\\n\\n\\n\\n위험: 실험 데이터 부족\\n\\n대응: 생성형 AI를 활용한 데이터 증강\\n\\n\\n\\n7.2 산업적 위험\\n\\n\\n위험: 글로벌 기업과의 경쟁\\n\\n대응: 차별화된 기술 개발 및 특허 전략\\n\\n\\n\\n위험: 기술 수용성\\n\\n대응: 단계적 도입 및 실증을 통한 신뢰성 확보\\n\\n\\n\\n8. 결론\\n본 제안서는 PFAS 대체 소재 개발을 위한 AI 기반 물성/합성 분석 기술 개발을 제안합니다. 최신 AI 기술과 고성능 컴퓨팅을 활용하여 95% 이상의 예측 정확도를 달성하고, 이를 통해 국내 소재 산업의 경쟁력을 강화할 수 있을 것으로 기대됩니다. 특히 글로벌 환경 규제 강화에 대응하여 선제적인 기술 개발이 필요하며, 이는 향후 2,579억 달러 규모의 이차전지 시장에서의 경쟁력 확보에 기여할 것입니다.\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\n        No description, website, or topics provided.\\n      \\nResources\\n\\n\\n\\n\\n\\n        Readme\\n \\n\\n\\n\\n\\n\\n\\nActivity \\nStars\\n\\n\\n\\n\\n0\\n      stars \\nWatchers\\n\\n\\n\\n\\n1\\n      watching \\nForks\\n\\n\\n\\n\\n0\\n      forks \\n\\n\\n          Report repository\\n \\n\\n\\n\\n\\n\\n\\nReleases\\nNo releases published\\n\\n\\n\\n\\n\\nPackages\\n      0\\n\\n        No packages published \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\n\\n\\n\\n\\n\\n\\n        © 2025 GitHub,\\xa0Inc.\\n      \\n\\n\\nFooter navigation\\n\\n\\nTerms\\n\\n\\nPrivacy\\n\\n\\nSecurity\\n\\n\\nStatus\\n\\n\\nDocs\\n\\n\\nContact\\n\\n\\n\\n\\n      Manage cookies\\n    \\n\\n\\n\\n\\n\\n      Do not share my personal information\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    You can’t perform that action at this time.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRaj_CwxYMby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}